<h1 align="center">Quantitative Signal Engine</h1>

<p align="center">
  <strong>Where Bayesian Model Averaging meets Kalman Filtering</strong><br>
  <sub>Multi-asset signal generation with calibrated uncertainty</sub>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/python-3.7+-blue.svg" alt="Python 3.7+">
  <img src="https://img.shields.io/badge/platform-macOS-lightgrey.svg" alt="macOS">
  <img src="https://img.shields.io/badge/assets-100+-green.svg" alt="100+ Assets">
  <img src="https://img.shields.io/badge/models-7_per_regime-orange.svg" alt="7 Models">
</p>

<p align="center">
  <a href="#the-system">The System</a> ‚Ä¢
  <a href="#quick-start">Quick Start</a> ‚Ä¢
  <a href="#daily-workflow">Daily Workflow</a> ‚Ä¢
  <a href="#command-reference">Commands</a> ‚Ä¢
  <a href="#the-mathematics">Mathematics</a> ‚Ä¢
  <a href="#architecture">Architecture</a>
</p>

---

## Why This System Exists

Most trading systems choose a single model and pretend it's correct. This system doesn't.

Instead, it maintains **7 competing models** across **5 market regimes**, letting Bayesian inference continuously update which models are most credible given recent data. Signals emerge from the **full posterior predictive distribution**‚Äînot from any single "best guess."

The result: **calibrated uncertainty**. When the system says "62% probability of positive return," it means that historically, 62% of such predictions were correct.

> *"The goal is not to be right. The goal is to know how confident you should be."*

---

## The System

This is a **belief evolution engine**, not a rule engine.

At its core, the system maintains a population of competing models‚Äîeach representing a different hypothesis about market dynamics. These models evolve in probability over time through Bayesian updating, and signals emerge from the full predictive distribution, not from point estimates.

### The Pipeline

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                                                                                       ‚ïë
‚ïë   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                                     ‚ïë
‚ïë   ‚îÇ Yahoo       ‚îÇ                                                                     ‚ïë
‚ïë   ‚îÇ Finance API ‚îÇ                                                                     ‚ïë
‚ïë   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                                                     ‚ïë
‚ïë          ‚îÇ                                                                            ‚ïë
‚ïë          ‚ñº                                                                            ‚ïë
‚ïë   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚ïë
‚ïë   ‚îÇ                         DATA ENGINE  (make data)                            ‚îÇ     ‚ïë
‚ïë   ‚îÇ                                                                             ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚Ä¢ Fetch 10 years OHLCV for 100+ symbols                                   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚Ä¢ Multi-pass retry (Yahoo is flaky)                                       ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚Ä¢ Incremental cache updates                                               ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚Ä¢ Currency conversion to PLN base                                         ‚îÇ     ‚ïë
‚ïë   ‚îÇ                                                                             ‚îÇ     ‚ïë
‚ïë   ‚îÇ   Output: src/data/options/stock_prices/{SYMBOL}_1d.csv                                              ‚îÇ     ‚ïë
‚ïë   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚ïë
‚ïë                                      ‚îÇ                                                ‚ïë
‚ïë                                      ‚ñº                                                ‚ïë
‚ïë   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚ïë
‚ïë   ‚îÇ                        TUNING ENGINE  (make tune)                           ‚îÇ     ‚ïë
‚ïë   ‚îÇ                                                                             ‚îÇ     ‚ïë
‚ïë   ‚îÇ   For each asset:                                                           ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ  For each regime r ‚àà {LOW_VOL_TREND, HIGH_VOL_TREND,                ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                       LOW_VOL_RANGE, HIGH_VOL_RANGE, CRISIS_JUMP}:  ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                                                                     ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ    For each model m ‚àà {kalman_gaussian,                             ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                        kalman_phi_gaussian,                         ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                        phi_student_t_nu_4,  phi_student_t_nu_6,     ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                        phi_student_t_nu_8,  phi_student_t_nu_12,    ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                        phi_student_t_nu_20}:                        ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                                                                     ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ      1. Fit Œ∏ = {q, c, œÜ} via MLE with regularization prior         ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ      2. Compute log-likelihood ‚Ñì(Œ∏)                                 ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ      3. Compute BIC = -2‚Ñì + k¬∑log(n)                                ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ      4. Compute Hyv√§rinen score (robust to misspecification)        ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ      5. Run PIT calibration diagnostics                             ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                                                                     ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ    Aggregate across models:                                         ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ      ‚Ä¢ w(m|r) = exp(-¬Ω ¬∑ ŒîBIC) ¬∑ hyv_weight^(1-Œ±)                   ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ      ‚Ä¢ Apply temporal smoothing: w ‚Üê w_prev^Œ± ¬∑ w_raw               ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ      ‚Ä¢ Apply hierarchical shrinkage toward global                   ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ      ‚Ä¢ Normalize: p(m|r) = w(m|r) / Œ£w                              ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ     ‚ïë
‚ïë   ‚îÇ                                                                             ‚îÇ     ‚ïë
‚ïë   ‚îÇ   Output: src/data/kalman_q_cache.json                           ‚îÇ     ‚ïë
‚ïë   ‚îÇ           {asset: {regime: {model: {q, œÜ, ŒΩ, BIC, p(m|r), ...}}}}           ‚îÇ     ‚ïë
‚ïë   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚ïë
‚ïë                                      ‚îÇ                                                ‚ïë
‚ïë                                      ‚ñº                                                ‚ïë
‚ïë   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚ïë
‚ïë   ‚îÇ                       SIGNAL ENGINE  (make stocks)                          ‚îÇ     ‚ïë
‚ïë   ‚îÇ                                                                             ‚îÇ     ‚ïë
‚ïë   ‚îÇ   For each asset:                                                           ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ  1. REGIME DETECTION                                                ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     ‚Ä¢ Compute rolling volatility (EWMA fast/slow blend)             ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     ‚Ä¢ Compute drift magnitude                                       ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     ‚Ä¢ Classify: r_t ‚àà {0,1,2,3,4}                                   ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                                                                     ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ  2. LOAD BELIEFS                                                    ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     ‚Ä¢ Retrieve p(m|r_t) and Œ∏_{r_t,m} from cache                    ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     ‚Ä¢ If regime sparse ‚Üí borrow from global (hierarchical)          ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                                                                     ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ  3. POSTERIOR PREDICTIVE MONTE CARLO                                ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     samples = []                                                    ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     for m, weight in p(m|r_t):                                      ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ         n_samples = weight √ó N_total                                ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ         for each sample:                                            ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ             Œº = kalman_drift_estimate                               ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ             for t in 1..horizon:                                    ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                 Œº ‚Üê œÜ¬∑Œº + Œ∑,  Œ∑ ~ N(0, q)                           ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                 r_t ‚Üê Œº + Œµ,  Œµ ~ model_distribution(œÉ)             ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ             samples.append(Œ£ r_t)                                   ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ                                                                     ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ  4. DECISION LAYER                                                  ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     ‚Ä¢ P(return > 0) = count(samples > 0) / N                        ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     ‚Ä¢ E[return] = mean(samples)                                     ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     ‚Ä¢ Apply exhaustion dampening (UE‚Üë/UE‚Üì)                          ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îÇ     ‚Ä¢ Map: P > 58% ‚Üí BUY, P < 42% ‚Üí SELL, else ‚Üí HOLD               ‚îÇ   ‚îÇ     ‚ïë
‚ïë   ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ     ‚ïë
‚ïë   ‚îÇ                                                                             ‚îÇ     ‚ïë
‚ïë   ‚îÇ   Output: Console tables + cached JSON                                      ‚îÇ     ‚ïë
‚ïë   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚ïë
‚ïë                                      ‚îÇ                                                ‚ïë
‚ïë                                      ‚ñº                                                ‚ïë
‚ïë                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚ïë
‚ïë                        ‚îÇ   BUY  ‚îÇ  HOLD  ‚îÇ  SELL   ‚îÇ                                  ‚ïë
‚ïë                        ‚îÇ   üü¢   ‚îÇ   ‚ö™   ‚îÇ   üî¥   ‚îÇ                                   ‚ïë
‚ïë                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚ïë
‚ïë                                                                                       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
```

### Quick Reference

| Engine | Command | Input | Output | Time |
|--------|---------|-------|--------|------|
| **Data** | `make data` | Yahoo Finance API | `data/*.csv` | 5-15 min |
| **Tuning** | `make tune` | Price CSVs | `kalman_q_cache.json` | 2-10 min |
| **Signal** | `make stocks` | Cache + fresh prices | Console + JSON | 1-3 min |

### Asset Universe

The system tracks **100+ assets** across multiple asset classes:

| Class | Examples | Count |
|-------|----------|-------|
| **Equities** | AAPL, MSFT, NVDA, TSLA, JPM, GS, UNH, LLY... | ~80 |
| **Defense** | LMT, RTX, NOC, GD, BA, HII, AVAV, PLTR... | ~40 |
| **ETFs** | SPY, VOO, GLD, SLV, SMH | 5 |
| **Commodities** | GC=F (Gold), SI=F (Silver) | 2 |
| **Crypto** | BTC-USD, MSTR | 2 |
| **FX** | PLNJPY=X | 1 |

All prices are converted to a common base currency (PLN) for portfolio-level analysis.

### Model Universe

The Tuning Engine fits **7 model classes** per regime:

| Model | Parameters | Use Case |
|-------|------------|----------|
| `kalman_gaussian` | q, c | Baseline Gaussian innovations |
| `kalman_phi_gaussian` | q, c, œÜ | AR(1) drift with Gaussian |
| `phi_student_t_nu_4` | q, c, œÜ | Heavy tails (ŒΩ=4) |
| `phi_student_t_nu_6` | q, c, œÜ | Moderate tails (ŒΩ=6) |
| `phi_student_t_nu_8` | q, c, œÜ | Light tails (ŒΩ=8) |
| `phi_student_t_nu_12` | q, c, œÜ | Near-Gaussian (ŒΩ=12) |
| `phi_student_t_nu_20` | q, c, œÜ | Almost Gaussian (ŒΩ=20) |

Student-t models use a **discrete ŒΩ grid** (not continuous optimization). Each ŒΩ is a separate sub-model in BMA, allowing the posterior to express uncertainty about tail thickness.

### Regime Classification

Markets are classified into **5 regimes** based on volatility and drift:

| Regime | Condition |
|--------|-----------|
| `LOW_VOL_TREND` | vol < 0.85√ómedian, \|drift\| > threshold |
| `HIGH_VOL_TREND` | vol > 1.3√ómedian, \|drift\| > threshold |
| `LOW_VOL_RANGE` | vol < 0.85√ómedian, \|drift\| ‚â§ threshold |
| `HIGH_VOL_RANGE` | vol > 1.3√ómedian, \|drift\| ‚â§ threshold |
| `CRISIS_JUMP` | vol > 2√ómedian OR tail_indicator > 4 |

Regime assignment is **deterministic and consistent** between tuning and inference.

---

## Quick Start

### Prerequisites

- macOS (Intel or Apple Silicon)
- Python 3.7+
- ~10GB disk space for price cache

### Installation (One Command)

```bash
make setup
```

This will:
1. Create `.venv/` virtual environment
2. Install dependencies from `src/setup/requirements.txt`
3. Download 10 years of price data (3 passes for reliability)
4. Clean cached data

**Time:** 5-15 minutes depending on network.

### Generate Your First Signals

```bash
make stocks
```

### What You'll See

The system outputs beautifully formatted Rich console tables with Apple-quality UX:

```
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ                    ‚ñ≤ NVDA  NVIDIA Corporation                                 ‚îÉ
‚îÉ                    142.58  ‚îÇ  LOW_VOL_TREND  ‚îÇ  2025-01-27  ‚îÇ  Student-t      ‚îÉ
‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ

  Horizon   ‚îÇ  P(r>0) ‚îÇ E[return] ‚îÇ      CI 68%       ‚îÇ   Profit ‚îÇ   Signal   ‚îÇ  Strength   
 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  1 day     ‚îÇ   54.2% ‚îÇ    +0.08% ‚îÇ [ -0.6%,  +0.7%]  ‚îÇ      +5k ‚îÇ   ‚Äî HOLD   ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  
  1 week    ‚îÇ   58.7% ‚îÇ    +0.42% ‚îÇ [ -1.3%,  +2.3%]  ‚îÇ     +49k ‚îÇ   ‚Üë BUY    ‚îÇ ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  
  1 month   ‚îÇ   63.1% ‚îÇ    +1.84% ‚îÇ [ -2.1%,  +5.3%]  ‚îÇ    +170k ‚îÇ   ‚Üë BUY    ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  
  3 months  ‚îÇ   71.2% ‚îÇ    +5.62% ‚îÇ [ -7.9%, +17.5%]  ‚îÇ    +618k ‚îÇ   ‚Üë BUY    ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  
  6 months  ‚îÇ   68.4% ‚îÇ    +9.93% ‚îÇ [-24.4%, +44.3%]  ‚îÇ    +1.7M ‚îÇ   ‚Üë BUY    ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë  
  12 months ‚îÇ   72.8% ‚îÇ   +19.80% ‚îÇ [-75.5%,+115.1%]  ‚îÇ    +6.2M ‚îÇ  ‚ñ≤‚ñ≤ BUY    ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë  

         P(r>0) prob of positive return    E[return] expected return    Profit on 1M PLN notional

                    ‚Üë BUY  P ‚â• 58%         ‚Äî HOLD  42% < P < 58%         ‚Üì SELL  P ‚â§ 42%
```

**Design Features:**
- **Perfect alignment** ‚Äî Rich Table ensures columns line up precisely
- **Alternating row colors** ‚Äî Subtle grey bands improve scannability
- **Strength bars** ‚Äî Visual confidence indicator (‚ñà‚ñë for signal, ‚îÄ for neutral)
- **Color hierarchy** ‚Äî Bright green (strong buy), green (buy), red (sell), dim (hold)
- **Signal badges** ‚Äî ‚ñ≤‚ñ≤ BUY, ‚Üë BUY, ‚Äî HOLD, ‚Üì SELL, ‚ñº‚ñº SELL
- **Header panel** ‚Äî Bordered card with asset identity and regime

Signals are color-coded:
- üü¢ **BUY** (green): P(r>0) ‚â• 58%
- ‚ö™ **HOLD** (dim): P(r>0) ‚àà (42%, 58%)
- üî¥ **SELL** (red): P(r>0) ‚â§ 42%

### Understanding the Columns

| Column | Meaning |
|--------|---------|
| **Horizon** | Forecast period (trading days) |
| **P(r>0)** | Probability that return will be positive |
| **E[return]** | Expected log return from posterior mean |
| **Signal** | Decision derived from probability threshold |
| **Confidence** | Visual indicator of probability magnitude |

### Understanding the Regime

Each asset is classified into one of 5 regimes:

| Regime | What It Means | Typical Behavior |
|--------|---------------|------------------|
| `LOW_VOL_TREND` | Quiet trending market | Smooth, directional moves |
| `HIGH_VOL_TREND` | Volatile trending market | Sharp moves with direction |
| `LOW_VOL_RANGE` | Quiet range-bound | Mean-reverting, choppy |
| `HIGH_VOL_RANGE` | Volatile range-bound | Whipsaw, no clear direction |
| `CRISIS_JUMP` | Extreme stress | Tail events, correlations spike |

The regime affects which model receives the most weight in the BMA mixture.

---

## Daily Workflow

### The 30-Second Morning Routine

```bash
make stocks
```

That's it. This single command:
1. Refreshes the last 5 days of price data
2. Loads cached Kalman parameters
3. Generates signals for all assets
4. Displays formatted output

### When to Re-Tune

The Tuning Engine should be run:
- **Weekly** during normal markets
- **After major regime shifts** (VIX spike, Fed announcement)
- **When signals feel stale** or miscalibrated

```bash
# Weekly calibration
make tune

# Force complete re-estimation (ignore cache)
make tune ARGS="--force"
```

### Offline Mode

Already have cached data? Work without network:

```bash
# Render from cache only
make report

# Or set environment variable
OFFLINE_MODE=1 make stocks
```

### Quick Validation

Before trusting signals, validate calibration:

```bash
# Check if probabilities match historical outcomes
make fx-calibration

# Quick smoke test with 20 assets
make top20
```

---

## Command Reference

All interaction happens through `make`. The Makefile orchestrates Python scripts, manages the virtual environment, and handles caching transparently.

---

### üöÄ Setup & Installation

#### `make setup`

**The one command to rule them all.** Run this once after cloning.

```bash
make setup
```

**What happens internally:**
1. Creates `.venv/` via `src/setup/setup_venv.sh`
2. Upgrades pip and installs `src/setup/requirements.txt`
3. Runs `ingestion/precache_data.py` **3 times** (Yahoo Finance is flaky)
4. Runs `ingestion/clean_cache.py` to remove empty rows

**Time:** 5-15 minutes  
**Disk:** ~10GB for full price cache

#### `make doctor`

Reinstalls all dependencies. Use when imports fail or packages are corrupted.

```bash
make doctor
```

---

### üìä Data Engine

The Data Engine fetches OHLCV (Open, High, Low, Close, Volume) from Yahoo Finance and caches locally as CSV files.

#### `make data`

Downloads full price history for all assets in the universe.

```bash
make data                              # Standard run
make data ARGS="--workers 4"           # Reduce parallelism
make data ARGS="--batch-size 8"        # Smaller batches
```

**Internals:**
- Runs `ingestion/refresh_data.py --skip-trim --retries 5 --workers 12 --batch-size 16`
- 5 retry passes (Yahoo Finance rate-limits aggressively)
- 12 parallel workers, 16 assets per batch
- Output: `src/data/options/stock_prices/<SYMBOL>_1d.csv`

#### `make refresh`

Updates only the last 5 days. Fast daily refresh.

```bash
make refresh
```

**Internals:**
- Deletes last 5 rows from each cache file
- Re-downloads with 5 retry passes
- Typical time: 2-5 minutes

#### `make clean-cache`

Removes rows with all-NaN values (dates before asset existed).

```bash
make clean-cache
```

#### `make failed`

Lists assets that failed to download (stored in `src/fx_failures.json`).

```bash
make failed
```

#### `make purge`

Deletes cache files for failed assets so they can be re-downloaded.

```bash
make purge                    # Clear cache for failed assets
make purge ARGS="--all"       # Also clear the failures list
```

---

### üîß Tuning Engine

The Tuning Engine estimates Kalman filter parameters via Maximum Likelihood Estimation, then applies Bayesian Model Averaging across model classes.

#### `make tune`

The heart of the calibration system.

```bash
make tune                              # Uses cache, skips already-tuned assets
make tune ARGS="--force"               # Re-estimate everything
make tune ARGS="--max-assets 10"       # Test with subset
make tune ARGS="--dry-run"             # Preview without executing
```

**What happens internally:**
1. Loads asset universe from `ingestion/data_utils.py`
2. For each asset, for each of 5 regimes:
   - Fits 7 model classes (Gaussian, AR(1)-Gaussian, Student-t with ŒΩ ‚àà {4,6,8,12,20})
   - Computes BIC, AIC, Hyv√§rinen score, PIT diagnostics
   - Converts scores to posterior weights
   - Applies temporal smoothing against previous run
   - Applies hierarchical shrinkage toward global
3. Saves to `src/data/kalman_q_cache.json`

**Key ARGS:**
| Argument | Description | Default |
|----------|-------------|---------|
| `--force` | Ignore cache, re-estimate all | False |
| `--max-assets N` | Process only first N assets | All |
| `--dry-run` | Preview without processing | False |
| `--prior-mean X` | Prior mean for log‚ÇÅ‚ÇÄ(q) | -6.0 |
| `--prior-lambda X` | Regularization strength | 1.0 |
| `--lambda-regime X` | Hierarchical shrinkage | 0.05 |
| `--debug` | Show stack traces on errors | False |

#### `make show-q`

Displays the cached Kalman parameters as raw JSON.

```bash
make show-q
```

#### `make clear-q`

Deletes the parameter cache. Next `make tune` will re-estimate everything.

```bash
make clear-q
```

---

### üìà Signal Engine

The Signal Engine consumes tuned parameters and generates Buy/Hold/Sell signals via posterior predictive Monte Carlo.

#### `make stocks`

**The main command for daily use.** Refreshes data, then generates signals.

```bash
make stocks                            # Full pipeline
make stocks ARGS="--assets AAPL,MSFT"  # Specific assets only
```

**What happens internally:**
1. Runs `ingestion/refresh_data.py` (updates last 5 days)
2. Runs `signals.py` with caching enabled
3. For each asset:
   - Determines current regime r_t
   - Loads model posterior p(m|r_t) from cache
   - Runs posterior predictive Monte Carlo
   - Computes expected utility across horizons
   - Maps to BUY/HOLD/SELL

**Output:** Beautiful Rich console tables showing:
- Signal per horizon (1d, 3d, 7d, 21d, 63d, 126d, 252d)
- Probability of positive return
- Expected log return
- Confidence indicators

#### `make report`

Renders signals from cache without network calls. Use when offline.

```bash
make report
```

#### `make top20`

Quick smoke test with first 20 assets. Good for testing changes.

```bash
make top20
```

---

### üî¨ Diagnostic Commands

These commands validate model quality and calibration.

#### `make fx-diagnostics`

Full diagnostic suite. **Expensive** (runs out-of-sample tests).

```bash
make fx-diagnostics
```

**Includes:**
- Log-likelihood analysis
- Parameter stability across time windows
- Out-of-sample predictive tests

#### `make fx-diagnostics-lite`

Lightweight diagnostics. Skips OOS tests.

```bash
make fx-diagnostics-lite
```

#### `make fx-calibration`

Probability Integral Transform (PIT) calibration check.

```bash
make fx-calibration
```

**What it tests:** If your 60% confidence intervals contain outcomes 60% of the time.

#### `make fx-model-comparison`

Compares model classes via AIC/BIC. Shows which models the posterior favors.

```bash
make fx-model-comparison
```

#### `make fx-validate-kalman`

Level-7 Kalman validation science:
- Drift estimation accuracy
- Likelihood surface analysis
- PIT histogram uniformity
- Stress regime behavior

```bash
make fx-validate-kalman                        # Console output only
make fx-validate-kalman-plots                  # Also saves plots to src/data/plots/kalman_validation/
```

#### `make tests`

Runs the unit test suite.

```bash
make tests
```

---

### üí∞ Debt Allocation Engine

A specialized decision engine for balance-sheet currency risk.

#### `make debt`

Determines the optimal day to switch JPY-denominated debt to EUR-denominated debt.

```bash
make debt
```

**This is NOT a trade signal.** It's a corporate treasury tool for:
- Balance-sheet convexity control
- Latent state inference (NORMAL ‚Üí COMPRESSED ‚Üí PRE_POLICY ‚Üí POLICY)
- Auditable, causal decision logic

Output: `src/data/debt/`

---

### üìã Options Screener & Backtesting

Legacy modules for equity options analysis.

#### `make run`

Runs the options screener with support/resistance analysis.

```bash
make run                                       # Uses tickers.csv
make run ARGS="--tickers AAPL,MSFT,NVDA"       # Explicit tickers
make run ARGS="--min_oi 200 --min_vol 50"      # Filter thresholds
```

**Output:**
- `screener_results.csv`
- `src/data/plots/<TICKER>_support_resistance.png`

#### `make backtest`

Multi-year strategy simulation with Black-Scholes pricing.

```bash
make backtest                                  # Uses tickers.csv
make backtest ARGS="--tickers AAPL --bt_years 5"
```

**Key ARGS:**

| Argument | Description | Default |
|----------|-------------|---------|
| `--bt_years` | Years of history | 3 |
| `--bt_dte` | Days to expiration | 7 |
| `--bt_moneyness` | OTM percent | 0.05 |
| `--bt_tp_x` | Take-profit multiple | None |
| `--bt_sl_x` | Stop-loss multiple | None |
| `--bt_alloc_frac` | Equity fraction per trade | 0.1 |

**Output:**
- `src/backtesting/equity_curves/<TICKER>_equity.csv`
- `screener_results_backtest.csv`

---

### üìä Fundamental Screeners

#### `make top50`

Ranks small/mid caps by 3-year revenue CAGR.

```bash
make top50
make top50 ARGS="--csv path/to/universe.csv"
```

#### `make bagger50`

Ranks by 100√ó Bagger Score (probability-weighted growth potential).

```bash
make bagger50
make bagger50 ARGS="--bagger_horizon 15"       # 15-year horizon
make bagger50 ARGS="--bagger_verbose"          # Show sub-scores
```

#### `make top100`

Top 100 screener using Russell 5000 universe.

```bash
make top100
```

#### `make build-russell`

Builds `src/data/russell/russell2500_tickers.csv` from public sources.

```bash
make build-russell
```

#### `make russell5000`

Builds the larger Russell 5000 universe.

```bash
make russell5000
```

---

### üßπ Utility Commands

#### `make clear`

Nuclear option. Clears all caches, plots, and temp files.

```bash
make clear
```

**Deletes:**
- `__pycache__/`
- `src/data/plots/*.png`
- `src/data/options/meta/`
- `data/*.backup`

#### `make colors`

Displays color palette test. Useful for terminal configuration.

```bash
make colors
```

---

## Architecture

```
python-options/
‚îÇ
‚îú‚îÄ‚îÄ Makefile                    # Command interface (start here)
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ tune.py           # TUNING ENGINE: MLE + BMA
‚îÇ   ‚îú‚îÄ‚îÄ tune_ux.py          # Tuning UX wrapper
‚îÇ   ‚îú‚îÄ‚îÄ signals.py   # SIGNAL ENGINE: Posterior predictive
‚îÇ   ‚îú‚îÄ‚îÄ signals_ux.py  # Rich console output
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/refresh_data.py         # DATA ENGINE: Bulk download
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/data_utils.py        # Data utilities + caching
‚îÇ   ‚îú‚îÄ‚îÄ debt_allocator.py       # Debt switch decision engine
‚îÇ   ‚îî‚îÄ‚îÄ quant/
‚îÇ       ‚îî‚îÄ‚îÄ cache/
‚îÇ           ‚îú‚îÄ‚îÄ tune/           # Tuned parameters (per-asset)
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ AAPL.json
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ MSFT.json
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ           ‚îî‚îÄ‚îÄ calibration/    # Calibration diagnostics
‚îÇ
‚îú‚îÄ‚îÄ data/                       # Price cache (CSV per symbol)
‚îú‚îÄ‚îÄ options.py                  # Options screener
‚îú‚îÄ‚îÄ src/backtesting/            # Backtesting module
‚îî‚îÄ‚îÄ src/data/plots/                      # Generated charts
```

### Design Principles

1. **Separation of concerns**
   - Tuning engine knows nothing about decisions
   - Signal engine acts on beliefs, doesn't create them
   - Presentation layer is fully decoupled

2. **Bayesian integrity**
   - When evidence is weak, the system becomes more ignorant, not more confident
   - Fallback is hierarchical: `p(m|r, weak data) ‚Üí p(m|global)`
   - Never synthesize beliefs that weren't learned

3. **Auditability**
   - All parameters cached and versioned
   - No hidden state mutations
   - Deterministic regime assignment

---

## Risk Temperature Governance (February 2026)

The system implements institutional-grade risk temperature governance based on the Chinese Quantitative Systems Professor's control theory approach. This layer modulates position sizing based on cross-asset stress indicators without touching distributional beliefs.

### Governance Features

| Feature | Description | Benefit |
|---------|-------------|---------|
| **Hysteresis Bands** | Asymmetric thresholds for regime transitions | Prevents oscillation at regime boundaries |
| **Conservative Imputation** | Missing data at 75th percentile | Defensive degradation when data quality deteriorates |
| **Rate Limiting** | Maximum temperature change of 0.3/day | Prevents whipsawing from single-day movements |
| **Dynamic Gap Risk** | 95th percentile of trailing 60-day gaps | Adaptive overnight budget constraint |
| **Complete Audit Trail** | Full attribution for reconstruction | Regulatory compliance and post-incident analysis |

### Regime State Machine

```
States: Calm ‚Üí Elevated ‚Üí Stressed ‚Üí Extreme

Upward Thresholds (always allowed):
    Calm ‚Üí Elevated:     temp > 0.5
    Elevated ‚Üí Stressed: temp > 1.0
    Stressed ‚Üí Extreme:  temp > 1.5

Downward Thresholds (with hysteresis gap):
    Extreme ‚Üí Stressed:  temp < 1.2   (gap of 0.3)
    Stressed ‚Üí Elevated: temp < 0.7   (gap of 0.3)
    Elevated ‚Üí Calm:     temp < 0.3   (gap of 0.2)
```

### Scale Factors by Regime

| Regime | Scale Factor | Position Effect |
|--------|-------------|-----------------|
| Calm | 100% | Full allocation |
| Elevated | 75% | Reduced exposure |
| Stressed | 45% | Significantly reduced |
| Extreme | 20% | Minimal / defensive |

### Usage

```python
from decision.metals_risk_temperature import compute_governed_metals_risk_temperature

# Compute with full governance
result = compute_governed_metals_risk_temperature(start_date="2020-01-01")

# Access governance information
print(f"Temperature: {result.temperature:.2f}")
print(f"Regime State: {result.regime_state}")
print(f"Scale Factor: {result.scale_factor:.2%}")

# Get complete audit trail
audit_json = result.get_audit_json()
human_readable = result.render_audit_trail()
```

### Key Files

- `src/decision/regime_governance.py` ‚Äî Core governance module
- `src/decision/metals_risk_temperature.py` ‚Äî Governed metals temperature
- `src/decision/risk_temperature.py` ‚Äî Main risk temperature with governance integration
- `src/tests/test_regime_governance.py` ‚Äî Comprehensive test suite

---

## The Mathematics

> *"The math always emerges from the underlying system‚Äînot the other way around."*

This section documents the mathematical foundations that govern each engine. The code implements these equations; understanding them illuminates why the system behaves as it does.

### Master Symbol Glossary

Before diving in, here's a complete reference of all mathematical symbols used:

#### Prices & Returns

| Symbol | Name | Meaning |
|--------|------|---------|
| P‚Çú | Price at time t | The asset price at time step t |
| r‚Çú | Return at time t | Log return: ln(P‚Çú/P‚Çú‚Çã‚ÇÅ) |
| h | Horizon | Forecast period in trading days |

#### Volatility

| Symbol | Name | Meaning |
|--------|------|---------|
| œÉ | Sigma | Standard deviation (volatility) |
| œÉ‚Çú¬≤ | Sigma squared | Variance at time t |
| Œª | Lambda | Decay factor in EWMA (0.94-0.97) |

#### Kalman Filter

| Symbol | Name | Meaning |
|--------|------|---------|
| Œº‚Çú | Mu | Latent (hidden) drift at time t |
| q | Process noise | How much drift can change per step |
| Œ∑‚Çú | Eta | Random shock to drift ~ N(0, q) |
| Œµ‚Çú | Epsilon | Observation noise ~ N(0, œÉ¬≤) |
| K | Kalman gain | Weight given to new observation (0-1) |
| P | State variance | Uncertainty in drift estimate |
| m | Posterior mean | Best estimate of drift after update |

#### AR(1) Model

| Symbol | Name | Meaning |
|--------|------|---------|
| œÜ | Phi | Mean-reversion coefficient (-1 to 1) |
| œÑ | Tau | Prior standard deviation for œÜ |

#### Student-t Distribution

| Symbol | Name | Meaning |
|--------|------|---------|
| ŒΩ | Nu | Degrees of freedom (tail thickness) |
| t_ŒΩ | Student-t | t-distribution with ŒΩ degrees of freedom |

#### Bayesian Inference

| Symbol | Name | Meaning |
|--------|------|---------|
| p(¬∑) | Probability | Probability or density function |
| p(m\|r) | Model posterior | Probability of model m given regime r |
| Œ∏ | Theta | Model parameters (q, œÜ, etc.) |
| ‚Ñì | Log-likelihood | Sum of log probabilities |

#### Model Selection

| Symbol | Name | Meaning |
|--------|------|---------|
| BIC | Bayesian Info Criterion | Penalized likelihood for model comparison |
| k | Parameter count | Number of free parameters in model |
| n | Sample size | Number of observations |
| w | Weight | Unnormalized model weight |
| Œ± | Alpha | Smoothing/blending coefficient |

#### Decision Theory

| Symbol | Name | Meaning |
|--------|------|---------|
| E[¬∑] | Expectation | Average value |
| P(¬∑) | Probability | Likelihood of event |
| EU | Expected Utility | Risk-adjusted expected value |
| f* | Optimal fraction | Kelly criterion bet size |
| z | Z-score | Standardized edge metric |

---

### Data Engine: Returns and Volatility

<details>
<summary><strong>üìñ Symbols used in this section</strong></summary>

| Symbol | Name | What it represents |
|--------|------|-------------------|
| r‚Çú | "r sub t" | The return at time t |
| P‚Çú | "P sub t" | The price at time t |
| P‚Çú‚Çã‚ÇÅ | "P sub t minus 1" | The price at the previous time step |
| log | Natural logarithm | ln(x), the inverse of eÀ£ |
| œÉ‚Çú¬≤ | "sigma squared sub t" | Variance (volatility squared) at time t |
| Œª | "lambda" | Decay factor controlling how fast old data fades |
| œÉ | "sigma" | Standard deviation (square root of variance) |

</details>

**Log Returns**

The system works with log returns, not simple returns:

```
r‚Çú = log(P‚Çú / P‚Çú‚Çã‚ÇÅ)
```

**In plain English:** *"Today's return equals the natural log of today's price divided by yesterday's price."*

Log returns are additive over time and approximately normal for small values, which simplifies the probabilistic machinery.

**Realized Volatility**

Volatility is estimated via exponentially-weighted moving average (EWMA):

```
œÉ‚Çú¬≤ = Œª ¬∑ œÉ‚Çú‚Çã‚ÇÅ¬≤ + (1 - Œª) ¬∑ r‚Çú¬≤
```

**In plain English:** *"Today's variance equals lambda times yesterday's variance, plus (1 - lambda) times today's squared return."*

**What this means:**
- When Œª = 0.94: Yesterday's variance gets 94% weight, today's return gets 6%
- Higher Œª = slower adaptation to new information
- Lower Œª = faster adaptation, more reactive

Where Œª ‚àà (0,1) controls decay. We use multiple speeds:
- **Fast** (Œª = 0.94): Responsive to recent moves
- **Slow** (Œª = 0.97): Smoother, less reactive

The final volatility blends both for robustness.

**Winsorization**

Extreme returns are clipped to reduce outlier influence:

```
r‚Çú ‚Üí clip(r‚Çú, -3œÉ, +3œÉ)
```

**In plain English:** *"If the return is more extreme than 3 standard deviations, cap it at 3 standard deviations."*

This makes parameter estimation more stable without discarding information entirely.

---

### Tuning Engine: Kalman Filter + MLE

<details>
<summary><strong>üìñ Symbols used in this section</strong></summary>

| Symbol | Name | What it represents |
|--------|------|-------------------|
| Œº‚Çú | "mu sub t" | Hidden (latent) drift at time t ‚Äî the "true" trend we're trying to estimate |
| Œº‚Çú‚Çã‚ÇÅ | "mu sub t minus 1" | Hidden drift at previous time step |
| Œ∑‚Çú | "eta sub t" | Random shock to the drift (process noise) |
| Œµ‚Çú | "epsilon sub t" | Observation noise (market randomness) |
| q | "q" | Process noise variance ‚Äî how much drift can change per step |
| œÉ‚Çú¬≤ | "sigma squared" | Observation noise variance (market volatility) |
| N(0, q) | Normal distribution | Gaussian with mean 0 and variance q |
| K | Kalman gain | How much weight to give new observations (0 to 1) |
| P | State variance | Our uncertainty about the drift estimate |
| m | Posterior mean | Our best estimate of drift after seeing data |
| m‚Çú | "m sub t" | Posterior mean at time t |
| ‚Ñì(q) | Log-likelihood | How well parameters explain the observed data |
| v‚Çú | Predictive variance | Total uncertainty before seeing observation |
| œÜ | "phi" | Mean-reversion coefficient in AR(1) model |
| œÑ | "tau" | Prior standard deviation for œÜ |
| ŒΩ | "nu" | Degrees of freedom in Student-t distribution |
| t_ŒΩ | Student-t | Heavy-tailed distribution with ŒΩ degrees of freedom |

</details>

**The State-Space Model**

We model latent drift Œº‚Çú as a random walk observed through noisy returns:

```
State equation:     Œº‚Çú = Œº‚Çú‚Çã‚ÇÅ + Œ∑‚Çú,     Œ∑‚Çú ~ N(0, q)
Observation:        r‚Çú = Œº‚Çú + Œµ‚Çú,       Œµ‚Çú ~ N(0, œÉ‚Çú¬≤)
```

**In plain English:**
- *"The true drift today equals yesterday's drift plus a random shock."*
- *"The observed return equals the true drift plus market noise."*

**What this means:**
- We never see Œº‚Çú directly ‚Äî it's hidden (latent)
- We only see r‚Çú (the actual return)
- The Kalman filter infers Œº‚Çú from the noisy observations

Here:
- **Œº‚Çú** is the unobserved "true" drift (what we're trying to estimate)
- **q** is the **process noise variance** (how much drift can change per step)
- **œÉ‚Çú¬≤** is the observation noise (market volatility)

**Kalman Filter Recursion**

Given prior Œº‚Çú‚Çã‚ÇÅ|‚Çú‚Çã‚ÇÅ ~ N(m, P), the Kalman filter updates:

```
Predict:    Œº‚Çú|‚Çú‚Çã‚ÇÅ ~ N(m, P + q)

Update:     K = (P + q) / (P + q + œÉ‚Çú¬≤)           # Kalman gain
            m‚Çú = m + K ¬∑ (r‚Çú - m)                  # Posterior mean
            P‚Çú = (1 - K) ¬∑ (P + q)                 # Posterior variance
```

**In plain English:**
1. **Predict:** *"Before seeing today's return, our uncertainty grows by q."*
2. **Kalman gain:** *"K measures how much to trust the new observation vs our prior belief."*
3. **Update mean:** *"New estimate = old estimate + K √ó (surprise)."*
4. **Update variance:** *"Our uncertainty shrinks after seeing data."*

**Intuition for Kalman gain K:**
- K close to 1: Trust the new observation heavily (high signal-to-noise)
- K close to 0: Stick with prior belief (low signal-to-noise)

The Kalman gain K ‚àà (0,1) balances prior belief against new evidence.

**Maximum Likelihood Estimation**

We find q by maximizing the log-likelihood:

```
‚Ñì(q) = Œ£‚Çú log p(r‚Çú | r‚ÇÅ:‚Çú‚Çã‚ÇÅ, q)
     = -¬Ω Œ£‚Çú [ log(2œÄ ¬∑ v‚Çú) + (r‚Çú - m‚Çú)¬≤ / v‚Çú ]
```

**In plain English:** *"Find the value of q that makes the observed returns most probable."*

Where v‚Çú = P + q + œÉ‚Çú¬≤ is the predictive variance (total uncertainty before observation).

**Regularization Prior**

To prevent overfitting, we add a Gaussian prior on log‚ÇÅ‚ÇÄ(q):

```
log‚ÇÅ‚ÇÄ(q) ~ N(Œº_prior, 1/Œª)
```

Default: Œº_prior = -6 (q ‚âà 10‚Åª‚Å∂), Œª = 1.0

**In plain English:** *"We believe q is probably around 0.000001, and penalize values far from this."*

The penalized objective becomes:

```
‚Ñì_penalized(q) = ‚Ñì(q) - Œª/2 ¬∑ (log‚ÇÅ‚ÇÄ(q) - Œº_prior)¬≤
```

**AR(1) Extension (œÜ-models)**

For mean-reverting drift, we extend the state equation:

```
Œº‚Çú = œÜ ¬∑ Œº‚Çú‚Çã‚ÇÅ + Œ∑‚Çú,     œÜ ‚àà (-1, 1)
```

**In plain English:** *"Today's drift equals phi times yesterday's drift, plus noise."*

**What œÜ values mean:**
- œÜ = 0: Drift has no memory (fully mean-reverting)
- œÜ = 0.9: Drift is very persistent (slow mean-reversion)
- œÜ = 1: Random walk (no mean-reversion) ‚Äî **unstable, we avoid this**
- œÜ < 0: Drift oscillates (rare in financial data)

When |œÜ| < 1, drift reverts toward zero. We apply a shrinkage prior:

```
œÜ ~ N(0, œÑ¬≤)
```

This prevents unit-root instability (œÜ ‚Üí 1).

**Student-t Innovations**

To capture fat tails, we replace Gaussian innovations with Student-t:

```
Œµ‚Çú ~ t_ŒΩ(0, œÉ‚Çú)
```

**In plain English:** *"Market noise follows a Student-t distribution instead of Gaussian, allowing for rare extreme moves."*

The degrees-of-freedom ŒΩ controls tail thickness:
- ŒΩ = 4: Very heavy tails (frequent extreme moves)
- ŒΩ = 20: Nearly Gaussian (rare extreme moves)
- ŒΩ ‚Üí ‚àû: Gaussian limit

We use a discrete grid ŒΩ ‚àà {4, 6, 8, 12, 20} and let BMA select the mixture.

---

### Tuning Engine: Bayesian Model Averaging

<details>
<summary><strong>üìñ Symbols used in this section</strong></summary>

| Symbol | Name | What it represents |
|--------|------|-------------------|
| p(¬∑) | Probability | Probability or probability density |
| p(m\|r) | "p of m given r" | Probability of model m, given we're in regime r |
| r‚Çú‚Çä‚Çï | "r sub t plus h" | Return h days from now |
| r | Regime | Market state (e.g., LOW_VOL_TREND) |
| m | Model | A specific model class (e.g., kalman_gaussian) |
| Œ∏ | "theta" | All parameters of a model (q, œÜ, etc.) |
| Œ∏·µ£,‚Çò | "theta r,m" | Parameters of model m in regime r |
| Œ£‚Çò | "sum over m" | Add up across all models |
| BIC | Bayesian Info Criterion | Score balancing fit vs complexity |
| ‚Ñì | Log-likelihood | How well model explains data |
| k | Parameter count | Number of free parameters |
| n | Sample size | Number of data points |
| w | Weight | Unnormalized probability |
| exp(¬∑) | Exponential | e raised to the power of (¬∑) |
| Œ± | "alpha" | Blending coefficient (0 to 1) |
| Œª | "lambda" | Shrinkage coefficient (0 to 1) |
| H(m) | Hyv√§rinen score | Robust model comparison metric |
| ‚àÇ | Partial derivative | Rate of change with respect to one variable |

</details>

**The BMA Equation**

Given regime r and model class m with parameters Œ∏, the posterior predictive is:

```
p(r‚Çú‚Çä‚Çï | r) = Œ£‚Çò p(r‚Çú‚Çä‚Çï | r, m, Œ∏·µ£,‚Çò) ¬∑ p(m | r)
```

**In plain English:** *"The probability of a future return equals the weighted average of each model's prediction, where weights are how much we trust each model."*

**Breaking it down:**
- p(r‚Çú‚Çä‚Çï | r, m, Œ∏) = "What does model m predict for the return?"
- p(m | r) = "How much do we trust model m in this regime?"
- Œ£‚Çò = "Add up across all 7 models"

This is the **core equation** of the system. Signals emerge from this mixture, not from any single "best" model.

**Model Weights via BIC**

For each model m in regime r, we compute BIC:

```
BIC_m,r = -2 ¬∑ ‚Ñì_m,r + k_m ¬∑ log(n_r)
```

**In plain English:** *"BIC = (how well it fits) minus (penalty for complexity)."*

**Breaking it down:**
- -2¬∑‚Ñì = Negative log-likelihood (lower is better fit)
- k¬∑log(n) = Penalty for having more parameters
- Models with more parameters must fit much better to justify the complexity

Where:
- ‚Ñì_m,r = maximized log-likelihood (how well model fits data)
- k_m = number of parameters (complexity penalty)
- n_r = sample size in regime r

Weights are softmax over negative BIC:

```
w_raw(m|r) = exp(-¬Ω ¬∑ (BIC_m,r - BIC_min,r))
p(m|r) = w_raw(m|r) / Œ£‚Çò' w_raw(m'|r)
```

**In plain English:** *"Convert BIC differences to probabilities using softmax. Lower BIC ‚Üí higher probability."*

**Hyv√§rinen Score (Robust Alternative)**

BIC assumes the true model is in the candidate set. When misspecified, the **Hyv√§rinen score** is more robust:

```
H(m) = Œ£‚Çú [ ‚àÇ¬≤log p / ‚àÇr¬≤ + ¬Ω(‚àÇlog p / ‚àÇr)¬≤ ]
```

**In plain English:** *"A scoring rule based on the curvature and slope of the log-density. Rewards models that are confident where they should be."*

**Why use it:**
- Works even when no model is "true"
- Naturally rewards accurate tail predictions
- Doesn't require computing normalizing constants

This is a **proper scoring rule** that doesn't require normalizing constants and naturally rewards tail accuracy.

We blend BIC and Hyv√§rinen:

```
w_combined(m) = w_bic(m)^Œ± ¬∑ w_hyvarinen(m)^(1-Œ±)
```

**In plain English:** *"Final weight is the geometric mean of BIC weight and Hyv√§rinen weight."*

Default Œ± = 0.5 (equal weighting).

**Temporal Smoothing**

To prevent erratic model switching, we smooth weights over time:

```
w_smooth(m|r) ‚àù w_prev(m|r)^Œ± ¬∑ w_raw(m|r)
```

**In plain English:** *"New weight = (yesterday's weight)^Œ± √ó (today's raw weight). This makes weights change gradually."*

With Œ± ‚âà 0.85, this creates "sticky" posteriors that adapt gradually.

**Hierarchical Shrinkage**

When regime r has few samples, we shrink toward the global posterior:

```
p(m|r) = (1 - Œª) ¬∑ p_local(m|r) + Œª ¬∑ p(m|global)
```

**In plain English:** *"When data is scarce, borrow strength from the overall (global) model weights."*

**What Œª controls:**
- Œª = 0: Use only local regime data
- Œª = 1: Ignore local data, use global weights entirely
- Default Œª = 0.05: Slight shrinkage toward global

Default Œª = 0.05. When samples < threshold, we set Œª = 1 (full borrowing) and mark `borrowed_from_global = True`.

---

### Signal Engine: Posterior Predictive Monte Carlo

<details>
<summary><strong>üìñ Symbols used in this section</strong></summary>

| Symbol | Name | What it represents |
|--------|------|-------------------|
| p(r‚Çú‚Çä‚Çï \| r_t) | Predictive distribution | Probability of future return given current regime |
| r‚Çú‚Çä‚Çï | "r sub t plus h" | Return h days from now |
| r_t | Current regime | Which of the 5 regimes we're in now |
| N_total | Total samples | Number of Monte Carlo samples (e.g., 10,000) |
| n_m | Samples for model m | Number of samples allocated to model m |
| w | Weight | Model probability p(m\|r) |
| Œº | "mu" | Current drift estimate |
| h | Horizon | Forecast period in days |
| q_m | Process noise for model m | Model-specific q parameter |
| œÉ | "sigma" | Volatility |
| P(r > 0) | Probability positive | Chance that return exceeds zero |
| E[r] | Expected return | Average (mean) return |

</details>

**Monte Carlo Sampling**

We approximate p(r‚Çú‚Çä‚Çï | r_t) via simulation:

```python
samples = []
for m, w in model_posterior.items():
    n_m = int(w * N_total)  # samples proportional to weight
    for _ in range(n_m):
        # Simulate Kalman path for h steps
        Œº = current_drift_estimate
        for step in range(h):
            Œº += sample_from(N(0, q_m))
            r_step = Œº + sample_from(distribution_m(œÉ))
        samples.append(sum_of_r_steps)
```

**In plain English:**
1. *"For each model, draw samples proportional to how much we trust it."*
2. *"For each sample, simulate the drift evolving over h days."*
3. *"Add up all the daily returns to get the h-day return."*
4. *"Collect all samples into one big distribution."*

**Why this works:**
- Models we trust more contribute more samples
- The final distribution automatically reflects model uncertainty
- We never pick a "best" model ‚Äî uncertainty is preserved

This produces samples from the full BMA mixture, not from any single model.

**Probability of Positive Return**

From the sample distribution:

```
P(r‚Çú‚Çä‚Çï > 0) = (# samples > 0) / N_total
```

**In plain English:** *"Count how many samples are positive, divide by total samples."*

This is the key quantity for BUY/HOLD/SELL decisions.

**Expected Log Return**

```
E[r‚Çú‚Çä‚Çï] = mean(samples)
```

**In plain English:** *"Average all the samples to get expected return."*

Used for position sizing and expected utility calculations.

**Signal Mapping**

Signals map from probability:

```
P(r > 0) ‚â• 0.58  ‚Üí  BUY
P(r > 0) ‚àà (0.42, 0.58)  ‚Üí  HOLD
P(r > 0) ‚â§ 0.42  ‚Üí  SELL
```

**In plain English:**
- *"If there's a 58%+ chance of positive return ‚Üí BUY"*
- *"If there's a 42% or less chance ‚Üí SELL"*
- *"Otherwise ‚Üí HOLD (not enough edge)"*

The 58%/42% thresholds derive from expected utility theory with symmetric loss.

---

### Signal Engine: Expected Utility

<details>
<summary><strong>üìñ Symbols used in this section</strong></summary>

| Symbol | Name | What it represents |
|--------|------|-------------------|
| EU | Expected Utility | Risk-adjusted expected value of a decision |
| p | Probability | Chance of winning |
| U(¬∑) | Utility function | How much we value an outcome |
| f* | "f star" | Optimal bet fraction (Kelly criterion) |
| b | Win/loss ratio | How much we win vs lose |
| z | Z-score | Standardized edge (like Sharpe ratio) |
| Œº | "mu" | Expected return (drift) |
| œÉ | "sigma" | Volatility (standard deviation) |
| h | Horizon | Forecast period in days |
| ‚àöh | Square root of h | Scaling factor for multi-day returns |
| z_adj | Adjusted z-score | Z-score after volatility dampening |
| œÉ_median | Median volatility | "Normal" volatility level |

</details>

**The EU Framework**

Decisions maximize expected utility, not expected return:

```
EU = p ¬∑ U(gain) + (1-p) ¬∑ U(loss)
```

**In plain English:** *"Expected utility = (chance of winning √ó value of winning) + (chance of losing √ó value of losing)."*

For Kelly-style sizing with log utility U(x) = log(1 + x):

```
f* = p - (1-p)/b
```

**In plain English:** *"Optimal bet size = probability of winning minus (probability of losing divided by win/loss ratio)."*

Where:
- f* = optimal fraction of capital to bet
- p = probability of win
- b = win/loss ratio (how much you win vs lose)

**Example:**
- p = 60%, b = 1.5 (win $1.50 for every $1 risked)
- f* = 0.60 - 0.40/1.5 = 0.60 - 0.27 = 0.33
- *"Bet 33% of capital"*

**Risk-Adjusted Edge**

We compute a Sharpe-style z-score:

```
z = (Œº / œÉ) ¬∑ ‚àöh
```

**In plain English:** *"Edge = (expected return / volatility) √ó square root of horizon."*

**Why ‚àöh?**
- Returns scale linearly with time: Œº √ó h
- Volatility scales with square root: œÉ √ó ‚àöh
- So Sharpe scales with ‚àöh

Where h is the horizon in days. This normalizes edge across timeframes.

**Volatility Regime Dampening**

In high-volatility regimes, we reduce conviction:

```
z_adj = z ¬∑ (1 - vol_penalty)
vol_penalty = max(0, (œÉ / œÉ_median - 1.5) ¬∑ 0.3)
```

**In plain English:** *"If volatility is 1.5√ó higher than normal, start reducing our edge estimate."*

**What this means:**
- œÉ/œÉ_median = 1.0 (normal vol): No penalty
- œÉ/œÉ_median = 1.5 (50% above normal): No penalty yet
- œÉ/œÉ_median = 2.0 (double normal): 15% penalty
- œÉ/œÉ_median = 3.0 (triple normal): 45% penalty

This prevents overconfidence when uncertainty is elevated.

---

### Debt Engine: Latent State Model

<details>
<summary><strong>üìñ Symbols used in this section</strong></summary>

| Symbol | Name | What it represents |
|--------|------|-------------------|
| S | State | Current latent (hidden) policy state |
| S‚Çú | "S sub t" | State at time t |
| S‚Çú‚Çã‚ÇÅ | "S sub t minus 1" | State at previous time step |
| Y | Observation vector | The 5 features we can measure |
| C | Convex loss | Asymmetric penalty for adverse moves |
| P | Tail mass | Probability of extreme outcomes |
| D | Disagreement | How much models disagree (entropy) |
| dD | Disagreement momentum | Rate of change in disagreement |
| V | Vol compression | Volatility relative to recent history |
| P(S\|Y) | State posterior | Probability of state given observations |
| Œ± | "alpha" | Decision threshold (e.g., 0.60) |
| ‚Üí | Transition arrow | Allowed state transition |

</details>

**State Space**

The debt allocator models policy stress via 4 latent states:

```
S ‚àà {NORMAL, COMPRESSED, PRE_POLICY, POLICY}
```

**In plain English:** *"The market is always in one of 4 hidden stress states."*

**What each state means:**

| State | Meaning | Typical Duration |
|-------|---------|------------------|
| NORMAL | Business as usual | Months |
| COMPRESSED | Vol suppressed, pressure building | Weeks |
| PRE_POLICY | Stress emerging, policy imminent | Days |
| POLICY | Active policy intervention | Days to weeks |

States are **partially ordered**: NORMAL ‚Üí COMPRESSED ‚Üí PRE_POLICY ‚Üí POLICY. Backward transitions are forbidden except via explicit reset.

**Observation Model**

We observe a 5-dimensional feature vector:

```
Y = (C, P, D, dD, V)

C  = Convex loss functional (asymmetric penalty for adverse moves)
P  = Tail mass (probability beyond threshold)
D  = Epistemic disagreement (entropy of model posterior)
dD = Disagreement momentum (rate of change in D)
V  = Volatility compression ratio (current vol / recent vol)
```

**In plain English:** *"We measure 5 things about the market that give clues about the hidden state."*

**Transition Dynamics**

State transitions follow a constrained Markov process:

```
P(S‚Çú | S‚Çú‚Çã‚ÇÅ, Y) ‚àù P(Y | S‚Çú) ¬∑ P(S‚Çú | S‚Çú‚Çã‚ÇÅ)
```

**In plain English:** *"The probability of being in a state depends on what we observe AND where we were before."*

With diagonal dominance (persistence ‚âà 0.85) and forward-only transitions.

**Decision Rule**

Switch debt when:

```
P(PRE_POLICY | Y) > Œ±
```

**In plain English:** *"If the probability of being in PRE_POLICY state exceeds our threshold, trigger the switch."*

Default Œ± = 0.60. The decision is **irreversible** (once triggered, done).

---

### Calibration: PIT Test

<details>
<summary><strong>üìñ Symbols used in this section</strong></summary>

| Symbol | Name | What it represents |
|--------|------|-------------------|
| u | Uniform value | Transformed probability (should be 0-1 uniform) |
| F | CDF | Cumulative Distribution Function (predicted) |
| F(x) | "F of x" | Probability that outcome ‚â§ x |
| r_actual | Actual return | The return that actually occurred |
| KS | Kolmogorov-Smirnov | Test statistic measuring calibration |
| sup | Supremum | Maximum value |
| F_empirical | Empirical CDF | CDF estimated from actual data |
| Uniform(0,1) | Uniform distribution | Every value between 0 and 1 equally likely |

</details>

**Probability Integral Transform**

If predictions are well-calibrated:

```
u = F(r_actual)  should be  ~ Uniform(0, 1)
```

**In plain English:** *"If we plug actual outcomes into our predicted CDF, the results should be uniformly distributed."*

**Why this works:**
- If you predict "30% chance of rain" and it rains 30% of the time when you say that, you're calibrated
- PIT is the formal version of this for continuous distributions
- If u values cluster near 0 or 1, predictions are systematically wrong

Where F is the predicted CDF (cumulative distribution function).

**KS Test**

We compute Kolmogorov-Smirnov statistic:

```
KS = sup_u | F_empirical(u) - u |
```

**In plain English:** *"Find the maximum gap between the empirical distribution of u values and the uniform line."*

p-value > 0.05 indicates calibration is acceptable.

**Interpretation**

| Pattern | KS Value | Meaning |
|---------|----------|---------|
| KS ‚âà 0 | < 0.05 | Perfect calibration ‚úì |
| KS moderate | 0.05-0.10 | Minor miscalibration |
| KS > 0.1 | > 0.10 | Significant miscalibration ‚úó |

**Visual patterns in PIT histogram:**
- **U-shape** (values cluster at 0 and 1): Overconfidence ‚Äî predictions are too narrow
- **‚à©-shape** (values cluster in middle): Underconfidence ‚Äî predictions are too wide
- **Flat** (uniform distribution): Well-calibrated ‚úì

---

### K=2 Mixture Model for Calibration Improvement

When single models fail PIT calibration (p-value < 0.05), the system automatically attempts a **K=2 mixture of symmetric œÜ-t models** to capture latent regime heterogeneity.

<details>
<summary><strong>üìñ Key Insight</strong></summary>

Calibration failures often occur not because the model has wrong parameters, but because markets alternate between **calm** and **stress** regimes within the estimation window. A single symmetric distribution cannot express this asymmetry.

The K=2 mixture solves this by allowing the predictive distribution to allocate mass asymmetrically **without breaking symmetry locally**.

</details>

**Model Definition**

```
p(r‚Çú | F‚Çú‚Çã‚ÇÅ) = w ¬∑ T·µ•(r‚Çú; Œº‚Çú, œÉ_A) + (1-w) ¬∑ T·µ•(r‚Çú; Œº‚Çú, œÉ_B)
```

Where:
- `œÜ` is **shared** across components (same drift dynamics)
- `ŒΩ` is **shared** (same tail thickness)
- `œÉ_A` = calm regime scale
- `œÉ_B` = stress regime scale, constrained: `œÉ_B ‚â• 1.5 √ó œÉ_A`
- `w ‚àà [0.1, 0.9]` = weight on calm component

**Interpretation**

| Component | œÉ | Role |
|-----------|---|------|
| A (calm) | œÉ_A (smaller) | Normal market conditions |
| B (stress) | œÉ_B (larger) | Crisis / tail events |

**Selection Logic**

The mixture model is only selected if:
1. Single model has calibration warning (PIT p < 0.05)
2. Mixture fitting succeeds
3. Mixture BIC < single model BIC - threshold

**Design Principles**

‚úì Asymmetry emerges from geometry (œÉ dispersion), not parameters
‚úì K=2 only (no K>2, prevents overfitting)
‚úì Shared œÜ and ŒΩ (maintains interpretability)
‚úì Static weights (no HMM complexity)
‚úì BIC-controlled selection (simpler model preferred)

---

### PIT-Driven Distribution Escalation (PDDE)

The system implements a **hierarchical model escalation** mechanism that automatically upgrades model complexity when diagnostics demand it.

<details>
<summary><strong>üìñ Core Principle</strong></summary>

> **Escalate model complexity only when diagnostics demand it.**
> Treat PIT failure as information ‚Äî not error.

Do NOT expand the global model grid blindly.
Refine locally, conditionally, and reversibly.

</details>

**Escalation Chain**

```
Level 0: œÜ-Gaussian
    ‚Üì (PIT p < 0.05)
Level 1: œÜ-Student-t (coarse ŒΩ grid: 4, 6, 8, 12, 20)
    ‚Üì (PIT fail at boundary ŒΩ)
Level 2: Adaptive ŒΩ Refinement (local grid expansion)
    ‚Üì (ŒΩ-refinement fails)
Level 3: K=2 Scale Mixture (œÉ dispersion for regime heterogeneity)
    ‚Üì (mixture fails, extreme kurtosis)
Level 4: EVT Tail Splice (GPD beyond threshold, rare)
```

**Escalation Triggers**

| Level | Trigger Condition | What It Does |
|-------|-------------------|--------------|
| 0 ‚Üí 1 | PIT p < 0.05 | Try heavier tails (Student-t) |
| 1 ‚Üí 2 | Best ŒΩ at boundary (12 or 20) | Refine ŒΩ locally |
| 2 ‚Üí 3 | ŒΩ-refinement fails | Try regime mixture |
| 3 ‚Üí 4 | Kurtosis > 10, mixture fails | Apply EVT tail splice |

**Output Contract**

Each asset records its escalation history:

```json
{
  "final_model": "phi-t | phi-t-refined | mixture | evt",
  "escalation_level": 0-4,
  "pit_ks_pvalue": 0.0823,
  "escalation_path": ["baseline_fit", "student_t_selected", "nu_refinement_attempted"],
  "justification": "diagnostic-driven"
}
```

**Files**

| File | Purpose |
|------|---------|
| `src/pit_driven_escalation.py` | Orchestration logic |
| `src/calibration/adaptive_nu_refinement.py` | Level 2: ŒΩ refinement |
| `src/calibration/phi_t_mixture_k2.py` | Level 3: K=2 mixture |
| `src/data/calibration/calibration_failures.json` | Diagnostic output |

**View Escalation Summary**

After running `make tune`, the summary shows escalation statistics:

```
üìà  MODEL SELECTION

    ‚óã Gaussian       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë   42  ( 35.0%)
    ‚óè Student-t      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë   78  ( 65.0%)

    ‚óÜ K=2 Mixture Fallback
      Attempted: 25  ‚Üí  Selected: 8  (32% success)

    ‚óá Adaptive ŒΩ Refinement
      Attempted: 15  ‚Üí  Improved: 6  (40% success)
```

---

### Summary: The Mathematical Contract

This box summarizes the entire system in symbols. Refer to the Master Symbol Glossary at the top of this section for definitions.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                             ‚îÇ
‚îÇ   DATA:     r‚Çú = log(P‚Çú/P‚Çú‚Çã‚ÇÅ)                               ‚îÇ
‚îÇ             œÉ‚Çú¬≤ = EWMA(r‚Çú¬≤)                                 ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ   TUNING:   Œº‚Çú = œÜŒº‚Çú‚Çã‚ÇÅ + Œ∑‚Çú        (state equation)         ‚îÇ
‚îÇ             r‚Çú = Œº‚Çú + Œµ‚Çú           (observation)            ‚îÇ
‚îÇ             q* = argmax ‚Ñì(q)       (MLE)                    ‚îÇ
‚îÇ             p(m|r) ‚àù exp(-BIC/2)   (BMA weights)            ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ   SIGNAL:   p(r|data) = Œ£‚Çò p(r|m,Œ∏) ¬∑ p(m|r)   (mixture)    ‚îÇ
‚îÇ             P(r>0) = ‚à´‚ÇÄ^‚àû p(r) dr              (probability)‚îÇ
‚îÇ             signal = map(P(r>0))               (decision)   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Line-by-line translation:**

| Line | Symbols | Plain English |
|------|---------|---------------|
| `r‚Çú = log(P‚Çú/P‚Çú‚Çã‚ÇÅ)` | Return = log(today's price / yesterday's price) | "Compute log returns" |
| `œÉ‚Çú¬≤ = EWMA(r‚Çú¬≤)` | Variance = exponentially-weighted average of squared returns | "Estimate volatility" |
| `Œº‚Çú = œÜŒº‚Çú‚Çã‚ÇÅ + Œ∑‚Çú` | Drift = phi √ó yesterday's drift + noise | "Drift evolves with mean-reversion" |
| `r‚Çú = Œº‚Çú + Œµ‚Çú` | Return = drift + noise | "Observed return is noisy drift" |
| `q* = argmax ‚Ñì(q)` | Optimal q = value that maximizes likelihood | "Find best-fit process noise" |
| `p(m\|r) ‚àù exp(-BIC/2)` | Model probability proportional to exp(-BIC/2) | "Weight models by BIC" |
| `p(r\|data) = Œ£‚Çò p(r\|m,Œ∏)¬∑p(m\|r)` | Prediction = weighted sum across models | "Average all model predictions" |
| `P(r>0) = ‚à´‚ÇÄ^‚àû p(r) dr` | Probability positive = integral from 0 to ‚àû | "Count positive samples" |
| `signal = map(P(r>0))` | Signal = function of probability | "Convert probability to BUY/HOLD/SELL" |

**The math is the system. The code merely implements it.**

---

## Cheat Sheet

### First Time Setup
```bash
make setup              # Install everything, download data
```

### Daily Use
```bash
make stocks             # The one command you need
```

### Weekly Maintenance
```bash
make tune               # Re-calibrate parameters
make stocks             # Generate fresh signals
```

### When Things Break
```bash
make doctor             # Reinstall dependencies
make failed             # See what failed
make purge              # Clear failed cache
make data               # Re-download everything
```

### Quick Reference Table

| I want to... | Command |
|--------------|---------|
| Generate signals | `make stocks` |
| Just see cached signals | `make report` |
| Re-tune all parameters | `make tune ARGS="--force"` |
| Test with few assets | `make top20` |
| Validate calibration | `make fx-calibration` |
| Clear everything | `make clear` |
| See what failed | `make failed` |
| Work offline | `OFFLINE_MODE=1 make stocks` |

---

## Troubleshooting

### Common Issues

**`zsh: command not found: python`**
```bash
echo 'alias python=python3' >> ~/.zshrc && source ~/.zshrc
```

**Build errors on Apple Silicon**
```bash
xcode-select --install
```

**Assets failing to download**
```bash
make failed    # See which assets failed
make purge     # Clear their cache
make data      # Re-download
```

**Stale parameters**
```bash
make clear-q   # Clear parameter cache
make tune      # Re-estimate
make stocks    # Fresh signals
```

### Environment Variables

| Variable | Description |
|----------|-------------|
| `PRICE_DATA_DIR` | Override data cache location |
| `NO_COLOR=1` | Disable colored output |
| `PYTHON` | Force specific interpreter |
| `OFFLINE_MODE=1` | Use cached data only, no network calls |

---

## Philosophy

### The Core Principle

> *"Act only on beliefs that were actually learned."*

This system is a **belief evolution engine**. It maintains competing hypotheses about market dynamics and lets Bayesian inference arbitrate between them.

### What Makes This Different

| Traditional Systems | This System |
|---------------------|-------------|
| Pick the "best" model | Maintain model uncertainty |
| Point estimates | Full distributions |
| Fixed parameters | Continuously re-calibrated |
| Confidence from conviction | Confidence from calibration |
| Fail silently when wrong | Know when you don't know |

### The Three Laws

1. **Never invent beliefs.** When evidence is weak, become more ignorant‚Äînot more confident. Fallback is always hierarchical (regime ‚Üí global), never fabricated.

2. **Preserve distributional integrity.** Decisions come from distributions, not point estimates. The signal layer sees samples, not parameters.

3. **Separate epistemology from agency.** The Tuning Engine learns beliefs. The Signal Engine acts on them. They never mix.

### The Goal

**Calibrated uncertainty**, not false precision.

When the system says "62% probability," it should be right 62% of the time. Not 70%. Not 55%. Exactly 62%.

That's what the PIT calibration tests verify. That's what makes this system trustworthy.

---

<h1 align="center">üáµüá± Wersja Polska / Polish Version</h1>

<p align="center">
  <strong>Pe≈Çne t≈Çumaczenie dokumentacji na jƒôzyk polski</strong>
</p>

---

## Dlaczego Ten System Istnieje

Wiƒôkszo≈õƒá system√≥w tradingowych wybiera jeden model i udaje, ≈ºe jest poprawny. Ten system tak nie dzia≈Ça.

Zamiast tego utrzymuje **7 konkurujƒÖcych modeli** w **5 re≈ºimach rynkowych**, pozwalajƒÖc bayesowskiemu wnioskowaniu ciƒÖgle aktualizowaƒá, kt√≥re modele sƒÖ najbardziej wiarygodne w ≈õwietle ostatnich danych. Sygna≈Çy wy≈ÇaniajƒÖ siƒô z **pe≈Çnego rozk≈Çadu predykcyjnego a posteriori** ‚Äî nie z pojedynczego "najlepszego przypuszczenia."

Rezultat: **skalibrowana niepewno≈õƒá**. Kiedy system m√≥wi "62% prawdopodobie≈Ñstwa dodatniego zwrotu," oznacza to, ≈ºe historycznie 62% takich prognoz okaza≈Ço siƒô trafnych.

> *"Celem nie jest mieƒá racjƒô. Celem jest wiedzieƒá, jak bardzo powiniene≈õ byƒá pewny."*

---

## System

To jest **silnik ewolucji przekona≈Ñ**, nie silnik regu≈Ç.

W swojej istocie system utrzymuje populacjƒô konkurujƒÖcych modeli ‚Äî ka≈ºdy reprezentuje innƒÖ hipotezƒô o dynamice rynku. Te modele ewoluujƒÖ w prawdopodobie≈Ñstwie w czasie poprzez bayesowskƒÖ aktualizacjƒô, a sygna≈Çy wy≈ÇaniajƒÖ siƒô z pe≈Çnego rozk≈Çadu predykcyjnego, nie z punktowych estymacji.

### Trzy Silniki

| Silnik | Komenda | Co Robi |
|--------|---------|---------|
| **Silnik Danych** | `make data` | Pobiera OHLCV dla 100+ aktyw√≥w, cachuje jako CSV |
| **Silnik Strojenia** | `make tune` | Dopasowuje parametry Kalmana przez MLE, oblicza wagi BMA |
| **Silnik Sygna≈Ç√≥w** | `make stocks` | Pr√≥bkuje rozk≈Çad predykcyjny, mapuje na sygna≈Çy |

### Uniwersum Aktyw√≥w

System ≈õledzi **100+ aktyw√≥w** w wielu klasach:

| Klasa | Przyk≈Çady | Liczba |
|-------|-----------|--------|
| **Akcje** | AAPL, MSFT, NVDA, TSLA, JPM, GS, UNH, LLY... | ~80 |
| **Obronno≈õƒá** | LMT, RTX, NOC, GD, BA, HII, AVAV, PLTR... | ~40 |
| **ETF-y** | SPY, VOO, GLD, SLV, SMH | 5 |
| **Towary** | GC=F (Z≈Çoto), SI=F (Srebro) | 2 |
| **Krypto** | BTC-USD, MSTR | 2 |
| **FX** | PLNJPY=X | 1 |

Wszystkie ceny sƒÖ przeliczane na wsp√≥lnƒÖ walutƒô bazowƒÖ (PLN) dla analizy na poziomie portfela.

### Uniwersum Modeli

Silnik Strojenia dopasowuje **7 klas modeli** na re≈ºim:

| Model | Parametry | Zastosowanie |
|-------|-----------|--------------|
| `kalman_gaussian` | q, c | Bazowe innowacje gaussowskie |
| `kalman_phi_gaussian` | q, c, œÜ | AR(1) dryft z gaussowskim |
| `phi_student_t_nu_4` | q, c, œÜ | Grube ogony (ŒΩ=4) |
| `phi_student_t_nu_6` | q, c, œÜ | Umiarkowane ogony (ŒΩ=6) |
| `phi_student_t_nu_8` | q, c, œÜ | Lekkie ogony (ŒΩ=8) |
| `phi_student_t_nu_12` | q, c, œÜ | Prawie gaussowski (ŒΩ=12) |
| `phi_student_t_nu_20` | q, c, œÜ | Niemal gaussowski (ŒΩ=20) |

Modele Student-t u≈ºywajƒÖ **dyskretnej siatki ŒΩ** (nie ciƒÖg≈Çej optymalizacji). Ka≈ºde ŒΩ jest osobnym podmodelem w BMA, pozwalajƒÖc posteriorowi wyra≈ºaƒá niepewno≈õƒá co do grubo≈õci ogon√≥w.

### Klasyfikacja Re≈ºim√≥w

Rynki sƒÖ klasyfikowane do **5 re≈ºim√≥w** na podstawie zmienno≈õci i dryftu:

| Re≈ºim | Warunek |
|-------|---------|
| `LOW_VOL_TREND` (niski vol, trend) | vol < 0.85√ómediana, \|dryft\| > pr√≥g |
| `HIGH_VOL_TREND` (wysoki vol, trend) | vol > 1.3√ómediana, \|dryft\| > pr√≥g |
| `LOW_VOL_RANGE` (niski vol, zakres) | vol < 0.85√ómediana, \|dryft\| ‚â§ pr√≥g |
| `HIGH_VOL_RANGE` (wysoki vol, zakres) | vol > 1.3√ómediana, \|dryft\| ‚â§ pr√≥g |
| `CRISIS_JUMP` (skok kryzysowy) | vol > 2√ómediana LUB wska≈∫nik_ogona > 4 |

Przypisanie re≈ºimu jest **deterministyczne i sp√≥jne** miƒôdzy strojeniem a wnioskowaniem.

---

## Szybki Start

### Wymagania

- macOS (Intel lub Apple Silicon)
- Python 3.7+
- ~10GB miejsca na dysku dla cache cen

### Instalacja (Jedna Komenda)

```bash
make setup
```

To wykona:
1. Utworzenie ≈õrodowiska wirtualnego `.venv/`
2. Instalacjƒô zale≈ºno≈õci z `src/setup/requirements.txt`
3. Pobranie 10 lat danych cenowych (3 przebiegi dla niezawodno≈õci)
4. Wyczyszczenie danych w cache

**Czas:** 5-15 minut w zale≈ºno≈õci od sieci.

### Wygeneruj Swoje Pierwsze Sygna≈Çy

```bash
make stocks
```

### Co Zobaczysz

System wy≈õwietla piƒôknie sformatowane tabele Rich z jako≈õciƒÖ UX Apple:

```
‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ                    ‚ñ≤ NVDA  NVIDIA Corporation                                 ‚îÉ
‚îÉ                    142.58  ‚îÇ  LOW_VOL_TREND  ‚îÇ  2025-01-27  ‚îÇ  Student-t      ‚îÉ
‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ

  Horyzont  ‚îÇ  P(r>0) ‚îÇ  E[zwrot] ‚îÇ      CI 68%       ‚îÇ    Zysk  ‚îÇ   Sygna≈Ç   ‚îÇ    Si≈Ça     
 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  1 dzie≈Ñ   ‚îÇ   54.2% ‚îÇ    +0.08% ‚îÇ [ -0.6%,  +0.7%]  ‚îÇ      +5k ‚îÇ  ‚Äî CZEKAJ  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  
  1 tydzie≈Ñ ‚îÇ   58.7% ‚îÇ    +0.42% ‚îÇ [ -1.3%,  +2.3%]  ‚îÇ     +49k ‚îÇ   ‚Üë KUP    ‚îÇ ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  
  1 miesiƒÖc ‚îÇ   63.1% ‚îÇ    +1.84% ‚îÇ [ -2.1%,  +5.3%]  ‚îÇ    +170k ‚îÇ   ‚Üë KUP    ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  
  3 miesiƒÖce‚îÇ   71.2% ‚îÇ    +5.62% ‚îÇ [ -7.9%, +17.5%]  ‚îÇ    +618k ‚îÇ   ‚Üë KUP    ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë  
  6 miesiƒôcy‚îÇ   68.4% ‚îÇ    +9.93% ‚îÇ [-24.4%, +44.3%]  ‚îÇ    +1.7M ‚îÇ   ‚Üë KUP    ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë  
  12 mies.  ‚îÇ   72.8% ‚îÇ   +19.80% ‚îÇ [-75.5%,+115.1%]  ‚îÇ    +6.2M ‚îÇ  ‚ñ≤‚ñ≤ KUP    ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë  

        P(r>0) prawdop. dodatniego zwrotu    E[zwrot] oczekiwany zwrot    Zysk na 1M PLN

                   ‚Üë KUP  P ‚â• 58%         ‚Äî CZEKAJ  42% < P < 58%        ‚Üì SPRZEDAJ  P ‚â§ 42%
```

**Cechy projektu:**
- **Idealne wyr√≥wnanie** ‚Äî Rich Table zapewnia precyzyjne wyr√≥wnanie kolumn
- **Naprzemienne kolory wierszy** ‚Äî Subtelne szare pasy poprawiajƒÖ czytelno≈õƒá
- **Paski si≈Çy** ‚Äî Wizualny wska≈∫nik pewno≈õci (‚ñà‚ñë dla sygna≈Çu, ‚îÄ dla neutralnego)
- **Hierarchia kolor√≥w** ‚Äî Jasny zielony (silny kup), zielony (kup), czerwony (sprzedaj), przyciemniony (czekaj)
- **Odznaki sygna≈Ç√≥w** ‚Äî ‚ñ≤‚ñ≤ KUP, ‚Üë KUP, ‚Äî CZEKAJ, ‚Üì SPRZEDAJ, ‚ñº‚ñº SPRZEDAJ
- **Panel nag≈Ç√≥wka** ‚Äî Karta z obramowaniem z identyfikacjƒÖ aktywa i re≈ºimem

Sygna≈Çy sƒÖ oznaczone kolorami:
- üü¢ **KUP** (zielony): P(r>0) ‚â• 58%
- ‚ö™ **CZEKAJ** (przygaszony): P(r>0) ‚àà (42%, 58%)
- üî¥ **SPRZEDAJ** (czerwony): P(r>0) ‚â§ 42%

### Zrozumienie Kolumn

| Kolumna | Znaczenie |
|---------|-----------|
| **Horyzont** | Okres prognozy (dni handlowe) |
| **P(r>0)** | Prawdopodobie≈Ñstwo, ≈ºe zwrot bƒôdzie dodatni |
| **E[zwrot]** | Oczekiwany log-zwrot ze ≈õredniej posteriori |
| **Sygna≈Ç** | Decyzja wynikajƒÖca z progu prawdopodobie≈Ñstwa |
| **Pewno≈õƒá** | Wizualny wska≈∫nik wielko≈õci prawdopodobie≈Ñstwa |

### Zrozumienie Re≈ºimu

Ka≈ºdy aktyw jest klasyfikowany do jednego z 5 re≈ºim√≥w:

| Re≈ºim | Co Oznacza | Typowe Zachowanie |
|-------|------------|-------------------|
| `LOW_VOL_TREND` | Cichy rynek trendujƒÖcy | G≈Çadkie, kierunkowe ruchy |
| `HIGH_VOL_TREND` | Zmienny rynek trendujƒÖcy | Ostre ruchy z kierunkiem |
| `LOW_VOL_RANGE` | Cichy rynek boczny | PowracajƒÖcy do ≈õredniej, szarpany |
| `HIGH_VOL_RANGE` | Zmienny rynek boczny | Whipsaw, brak jasnego kierunku |
| `CRISIS_JUMP` | Ekstremalny stres | Zdarzenia ogonowe, korelacje rosnƒÖ |

Re≈ºim wp≈Çywa na to, kt√≥ry model otrzymuje najwiƒôkszƒÖ wagƒô w mieszance BMA.

---

## Dzienny Przep≈Çyw Pracy

### 30-Sekundowa Poranna Rutyna

```bash
make stocks
```

To wszystko. Ta pojedyncza komenda:
1. Od≈õwie≈ºa ostatnie 5 dni danych cenowych
2. ≈Åaduje zapisane parametry Kalmana
3. Generuje sygna≈Çy dla wszystkich aktyw√≥w
4. Wy≈õwietla sformatowane wyj≈õcie

### Kiedy Ponownie Stroiƒá

Silnik Strojenia powinien byƒá uruchamiany:
- **Co tydzie≈Ñ** podczas normalnych rynk√≥w
- **Po du≈ºych zmianach re≈ºimu** (skok VIX, og≈Çoszenie Fed)
- **Gdy sygna≈Çy wydajƒÖ siƒô nieaktualne** lub ≈∫le skalibrowane

```bash
# Cotygodniowa kalibracja
make tune

# Wymu≈õ pe≈ÇnƒÖ re-estymacjƒô (ignoruj cache)
make tune ARGS="--force"
```

### Tryb Offline

Masz ju≈º dane w cache? Pracuj bez sieci:

```bash
# Renderuj tylko z cache
make report

# Lub ustaw zmiennƒÖ ≈õrodowiskowƒÖ
OFFLINE_MODE=1 make stocks
```

---

## Referencja Komend

### G≈Ç√≥wne Komendy

| Komenda | Opis |
|---------|------|
| `make setup` | Pe≈Çna konfiguracja: venv + zale≈ºno≈õci + dane (uruchom raz) |
| `make data` | Pobierz wszystkie dane cenowe (5 pr√≥b) |
| `make refresh` | Od≈õwie≈º ostatnie 5 dni danych |
| `make tune` | Kalibruj parametry Kalmana |
| `make stocks` | **G≈Ç√≥wna komenda:** od≈õwie≈º + sygna≈Çy |
| `make report` | Renderuj sygna≈Çy z cache (offline) |

### Komendy Strojenia

| Komenda | Opis |
|---------|------|
| `make tune` | Str√≥j wszystkie aktywa (u≈ºywa cache) |
| `make tune ARGS="--force"` | Wymu≈õ re-estymacjƒô |
| `make show-q` | Wy≈õwietl zapisane parametry |
| `make clear-q` | Wyczy≈õƒá cache parametr√≥w |

### Komendy Diagnostyczne

| Komenda | Opis |
|---------|------|
| `make fx-diagnostics` | Pe≈Çna diagnostyka (kosztowna) |
| `make fx-diagnostics-lite` | Lekka diagnostyka |
| `make fx-calibration` | Sprawdzenie kalibracji PIT |
| `make fx-model-comparison` | Por√≥wnanie modeli AIC/BIC |
| `make fx-validate-kalman` | Walidacja filtru Kalmana |
| `make tests` | Uruchom testy jednostkowe |

### Komendy Narzƒôdziowe

| Komenda | Opis |
|---------|------|
| `make doctor` | Przeinstaluj zale≈ºno≈õci |
| `make failed` | Lista nieudanych aktyw√≥w |
| `make purge` | Wyczy≈õƒá cache dla nieudanych aktyw√≥w |
| `make clear` | Wyczy≈õƒá wszystkie cache |
| `make clean-cache` | Usu≈Ñ puste wiersze |
| `make top20` | Szybki test z 20 aktywami |

---

## Matematyka

> *"Matematyka zawsze wy≈Çania siƒô z bazowego systemu ‚Äî nie odwrotnie."*

Ta sekcja dokumentuje fundamenty matematyczne rzƒÖdzƒÖce ka≈ºdym silnikiem.

### G≈Ç√≥wny S≈Çownik Symboli

#### Ceny i Zwroty

| Symbol | Nazwa | Znaczenie |
|--------|-------|-----------|
| P‚Çú | Cena w czasie t | Cena aktywa w kroku czasowym t |
| r‚Çú | Zwrot w czasie t | Log-zwrot: ln(P‚Çú/P‚Çú‚Çã‚ÇÅ) |
| h | Horyzont | Okres prognozy w dniach handlowych |

#### Zmienno≈õƒá

| Symbol | Nazwa | Znaczenie |
|--------|-------|-----------|
| œÉ | Sigma | Odchylenie standardowe (zmienno≈õƒá) |
| œÉ‚Çú¬≤ | Sigma kwadrat | Wariancja w czasie t |
| Œª | Lambda | Wsp√≥≈Çczynnik zaniku w EWMA (0.94-0.97) |

#### Filtr Kalmana

| Symbol | Nazwa | Znaczenie |
|--------|-------|-----------|
| Œº‚Çú | Mu | Ukryty (latentny) dryft w czasie t |
| q | Szum procesu | O ile dryft mo≈ºe zmieniƒá siƒô na krok |
| Œ∑‚Çú | Eta | Losowy szok do dryftu ~ N(0, q) |
| Œµ‚Çú | Epsilon | Szum obserwacji ~ N(0, œÉ¬≤) |
| K | Wzmocnienie Kalmana | Waga nadana nowej obserwacji (0-1) |
| P | Wariancja stanu | Niepewno≈õƒá w estymacji dryftu |
| m | ≈örednia posteriori | Najlepsza estymacja dryftu po aktualizacji |

#### Model AR(1)

| Symbol | Nazwa | Znaczenie |
|--------|-------|-----------|
| œÜ | Phi | Wsp√≥≈Çczynnik powrotu do ≈õredniej (-1 do 1) |
| œÑ | Tau | Priorytetowe odchylenie standardowe dla œÜ |

#### Rozk≈Çad Studenta-t

| Symbol | Nazwa | Znaczenie |
|--------|-------|-----------|
| ŒΩ | Nu | Stopnie swobody (grubo≈õƒá ogon√≥w) |
| t_ŒΩ | Student-t | Rozk≈Çad t z ŒΩ stopniami swobody |

#### Wnioskowanie Bayesowskie

| Symbol | Nazwa | Znaczenie |
|--------|-------|-----------|
| p(¬∑) | Prawdopodobie≈Ñstwo | Funkcja prawdopodobie≈Ñstwa lub gƒôsto≈õci |
| p(m\|r) | Posterior modelu | Prawdopodobie≈Ñstwo modelu m przy re≈ºimie r |
| Œ∏ | Theta | Parametry modelu (q, œÜ, itd.) |
| ‚Ñì | Log-wiarygodno≈õƒá | Suma logarytm√≥w prawdopodobie≈Ñstw |

#### Selekcja Modeli

| Symbol | Nazwa | Znaczenie |
|--------|-------|-----------|
| BIC | Bayesowskie Kryterium Inf. | Penalizowana wiarygodno≈õƒá do por√≥wna≈Ñ |
| k | Liczba parametr√≥w | Liczba wolnych parametr√≥w w modelu |
| n | Wielko≈õƒá pr√≥by | Liczba obserwacji |
| w | Waga | Nieznormalizowana waga modelu |
| Œ± | Alfa | Wsp√≥≈Çczynnik wyg≈Çadzania/mieszania |

#### Teoria Decyzji

| Symbol | Nazwa | Znaczenie |
|--------|-------|-----------|
| E[¬∑] | Warto≈õƒá oczekiwana | ≈örednia warto≈õƒá |
| P(¬∑) | Prawdopodobie≈Ñstwo | Szansa zdarzenia |
| EU | Oczekiwana U≈ºyteczno≈õƒá | Skorygowana o ryzyko warto≈õƒá oczekiwana |
| f* | Optymalna frakcja | Wielko≈õƒá zak≈Çadu wg kryterium Kelly'ego |
| z | Z-score | Standaryzowana metryka przewagi |

---

### Silnik Danych: Zwroty i Zmienno≈õƒá

**Log-Zwroty**

System pracuje z log-zwrotami, nie prostymi zwrotami:

```
r‚Çú = log(P‚Çú / P‚Çú‚Çã‚ÇÅ)
```

**Po polsku:** *"Dzisiejszy zwrot r√≥wna siƒô logarytmowi naturalnemu z dzisiejszej ceny podzielonej przez wczorajszƒÖ cenƒô."*

**Zrealizowana Zmienno≈õƒá**

Zmienno≈õƒá jest estymowana przez wyk≈Çadniczo-wa≈ºonƒÖ ≈õredniƒÖ ruchomƒÖ (EWMA):

```
œÉ‚Çú¬≤ = Œª ¬∑ œÉ‚Çú‚Çã‚ÇÅ¬≤ + (1 - Œª) ¬∑ r‚Çú¬≤
```

**Po polsku:** *"Dzisiejsza wariancja r√≥wna siƒô lambda razy wczorajsza wariancja, plus (1 - lambda) razy dzisiejszy zwrot do kwadratu."*

**Co to oznacza:**
- Gdy Œª = 0.94: Wczorajsza wariancja dostaje 94% wagi, dzisiejszy zwrot 6%
- Wy≈ºsze Œª = wolniejsza adaptacja do nowych informacji
- Ni≈ºsze Œª = szybsza adaptacja, bardziej reaktywne

**Winsoryzacja**

Ekstremalne zwroty sƒÖ przycinane, aby zmniejszyƒá wp≈Çyw warto≈õci odstajƒÖcych:

```
r‚Çú ‚Üí clip(r‚Çú, -3œÉ, +3œÉ)
```

**Po polsku:** *"Je≈õli zwrot jest bardziej ekstremalny ni≈º 3 odchylenia standardowe, ogranicz go do 3 odchyle≈Ñ standardowych."*

---

### Silnik Strojenia: Filtr Kalmana + MLE

**Model Przestrzeni Stan√≥w**

Modelujemy latentny dryft Œº‚Çú jako b≈ÇƒÖdzenie losowe obserwowane przez zaszumione zwroty:

```
R√≥wnanie stanu:      Œº‚Çú = Œº‚Çú‚Çã‚ÇÅ + Œ∑‚Çú,     Œ∑‚Çú ~ N(0, q)
Obserwacja:          r‚Çú = Œº‚Çú + Œµ‚Çú,       Œµ‚Çú ~ N(0, œÉ‚Çú¬≤)
```

**Po polsku:**
- *"Prawdziwy dryft dzisiaj r√≥wna siƒô wczorajszemu dryftowi plus losowy szok."*
- *"Obserwowany zwrot r√≥wna siƒô prawdziwemu dryftowi plus szum rynkowy."*

**Rekurencja Filtru Kalmana**

Przy danym priorze Œº‚Çú‚Çã‚ÇÅ|‚Çú‚Çã‚ÇÅ ~ N(m, P), filtr Kalmana aktualizuje:

```
Predykcja:  Œº‚Çú|‚Çú‚Çã‚ÇÅ ~ N(m, P + q)

Aktualizacja: K = (P + q) / (P + q + œÉ‚Çú¬≤)     # Wzmocnienie Kalmana
              m‚Çú = m + K ¬∑ (r‚Çú - m)            # ≈örednia posteriori
              P‚Çú = (1 - K) ¬∑ (P + q)           # Wariancja posteriori
```

**Po polsku:**
1. **Predykcja:** *"Przed zobaczeniem dzisiejszego zwrotu, nasza niepewno≈õƒá ro≈õnie o q."*
2. **Wzmocnienie Kalmana:** *"K mierzy, ile ufaƒá nowej obserwacji vs. naszemu priorowi."*
3. **Aktualizacja ≈õredniej:** *"Nowa estymacja = stara estymacja + K √ó (niespodzianka)."*
4. **Aktualizacja wariancji:** *"Nasza niepewno≈õƒá maleje po zobaczeniu danych."*

**Estymacja Najwiƒôkszej Wiarygodno≈õci (MLE)**

Znajdujemy q maksymalizujƒÖc log-wiarygodno≈õƒá:

```
‚Ñì(q) = Œ£‚Çú log p(r‚Çú | r‚ÇÅ:‚Çú‚Çã‚ÇÅ, q)
```

**Po polsku:** *"Znajd≈∫ warto≈õƒá q, kt√≥ra sprawia, ≈ºe obserwowane zwroty sƒÖ najbardziej prawdopodobne."*

**Rozszerzenie AR(1) (modele œÜ)**

Dla dryftu powracajƒÖcego do ≈õredniej, rozszerzamy r√≥wnanie stanu:

```
Œº‚Çú = œÜ ¬∑ Œº‚Çú‚Çã‚ÇÅ + Œ∑‚Çú,     œÜ ‚àà (-1, 1)
```

**Po polsku:** *"Dzisiejszy dryft r√≥wna siƒô phi razy wczorajszy dryft, plus szum."*

**Co oznaczajƒÖ warto≈õci œÜ:**
- œÜ = 0: Dryft nie ma pamiƒôci (pe≈Çny powr√≥t do ≈õredniej)
- œÜ = 0.9: Dryft jest bardzo trwa≈Çy (wolny powr√≥t do ≈õredniej)
- œÜ = 1: B≈ÇƒÖdzenie losowe (brak powrotu do ≈õredniej) ‚Äî **niestabilne, unikamy**
- œÜ < 0: Dryft oscyluje (rzadkie w danych finansowych)

**Innowacje Studenta-t**

Aby uchwyciƒá grube ogony, zastƒôpujemy gaussowskie innowacje rozk≈Çadem Studenta-t:

```
Œµ‚Çú ~ t_ŒΩ(0, œÉ‚Çú)
```

**Po polsku:** *"Szum rynkowy podƒÖ≈ºa za rozk≈Çadem Studenta-t zamiast gaussowskiego, pozwalajƒÖc na rzadkie ekstremalne ruchy."*

---

### Silnik Strojenia: Bayesowskie U≈õrednianie Modeli

**R√≥wnanie BMA**

Przy danym re≈ºimie r i klasie modelu m z parametrami Œ∏, rozk≈Çad predykcyjny posteriori to:

```
p(r‚Çú‚Çä‚Çï | r) = Œ£‚Çò p(r‚Çú‚Çä‚Çï | r, m, Œ∏·µ£,‚Çò) ¬∑ p(m | r)
```

**Po polsku:** *"Prawdopodobie≈Ñstwo przysz≈Çego zwrotu r√≥wna siƒô wa≈ºonej ≈õredniej prognoz ka≈ºdego modelu, gdzie wagi to ile ufamy ka≈ºdemu modelowi."*

To jest **g≈Ç√≥wne r√≥wnanie** systemu. Sygna≈Çy wy≈ÇaniajƒÖ siƒô z tej mieszanki, nie z ≈ºadnego pojedynczego "najlepszego" modelu.

**Wagi Modeli przez BIC**

Dla ka≈ºdego modelu m w re≈ºimie r, obliczamy BIC:

```
BIC_m,r = -2 ¬∑ ‚Ñì_m,r + k_m ¬∑ log(n_r)
```

**Po polsku:** *"BIC = (jak dobrze pasuje) minus (kara za z≈Ço≈ºono≈õƒá)."*

**Wyg≈Çadzanie Czasowe**

Aby zapobiec gwa≈Çtownemu prze≈ÇƒÖczaniu modeli, wyg≈Çadzamy wagi w czasie:

```
w_smooth(m|r) ‚àù w_prev(m|r)^Œ± ¬∑ w_raw(m|r)
```

**Po polsku:** *"Nowa waga = (wczorajsza waga)^Œ± √ó (dzisiejsza surowa waga). To sprawia, ≈ºe wagi zmieniajƒÖ siƒô stopniowo."*

**Hierarchiczne Kurczenie**

Gdy re≈ºim r ma ma≈Ço pr√≥bek, kurczymy w kierunku globalnego posterioru:

```
p(m|r) = (1 - Œª) ¬∑ p_local(m|r) + Œª ¬∑ p(m|global)
```

**Po polsku:** *"Gdy danych jest ma≈Ço, po≈ºyczaj si≈Çƒô z og√≥lnych (globalnych) wag modeli."*

---

### Silnik Sygna≈Ç√≥w: Monte Carlo Predykcyjne Posteriori

**Pr√≥bkowanie Monte Carlo**

Przybli≈ºamy p(r‚Çú‚Çä‚Çï | r_t) przez symulacjƒô:

```python
samples = []
for m, w in model_posterior.items():
    n_m = int(w * N_total)  # pr√≥bki proporcjonalne do wagi
    for _ in range(n_m):
        Œº = current_drift_estimate
        for step in range(h):
            Œº += sample_from(N(0, q_m))
            r_step = Œº + sample_from(distribution_m(œÉ))
        samples.append(sum_of_r_steps)
```

**Po polsku:**
1. *"Dla ka≈ºdego modelu, losuj pr√≥bki proporcjonalnie do tego, jak bardzo mu ufamy."*
2. *"Dla ka≈ºdej pr√≥bki, symuluj ewolucjƒô dryftu przez h dni."*
3. *"Zsumuj wszystkie dzienne zwroty, aby uzyskaƒá zwrot h-dniowy."*
4. *"Zbierz wszystkie pr√≥bki w jeden du≈ºy rozk≈Çad."*

**Prawdopodobie≈Ñstwo Dodatniego Zwrotu**

Z rozk≈Çadu pr√≥bek:

```
P(r‚Çú‚Çä‚Çï > 0) = (# pr√≥bek > 0) / N_total
```

**Po polsku:** *"Policz ile pr√≥bek jest dodatnich, podziel przez ca≈ÇkowitƒÖ liczbƒô pr√≥bek."*

**Mapowanie Sygna≈Ç√≥w**

Sygna≈Çy mapujƒÖ z prawdopodobie≈Ñstwa:

```
P(r > 0) ‚â• 0.58  ‚Üí  KUP
P(r > 0) ‚àà (0.42, 0.58)  ‚Üí  CZEKAJ
P(r > 0) ‚â§ 0.42  ‚Üí  SPRZEDAJ
```

**Po polsku:**
- *"Je≈õli jest 58%+ szans na dodatni zwrot ‚Üí KUP"*
- *"Je≈õli jest 42% lub mniej szans ‚Üí SPRZEDAJ"*
- *"W przeciwnym razie ‚Üí CZEKAJ (niewystarczajƒÖca przewaga)"*

---

### Silnik Sygna≈Ç√≥w: Oczekiwana U≈ºyteczno≈õƒá

**Ramy EU**

Decyzje maksymalizujƒÖ oczekiwanƒÖ u≈ºyteczno≈õƒá, nie oczekiwany zwrot:

```
EU = p ¬∑ U(zysk) + (1-p) ¬∑ U(strata)
```

**Po polsku:** *"Oczekiwana u≈ºyteczno≈õƒá = (szansa wygranej √ó warto≈õƒá wygranej) + (szansa przegranej √ó warto≈õƒá przegranej)."*

Dla rozmiaru pozycji w stylu Kelly'ego z logarytmicznƒÖ u≈ºyteczno≈õciƒÖ U(x) = log(1 + x):

```
f* = p - (1-p)/b
```

**Po polsku:** *"Optymalna wielko≈õƒá zak≈Çadu = prawdopodobie≈Ñstwo wygranej minus (prawdopodobie≈Ñstwo przegranej podzielone przez stosunek wygrana/przegrana)."*

**Przyk≈Çad:**
- p = 60%, b = 1.5 (wygrana $1.50 za ka≈ºdy zaryzykowany $1)
- f* = 0.60 - 0.40/1.5 = 0.60 - 0.27 = 0.33
- *"Postaw 33% kapita≈Çu"*

---

### Kalibracja: Test PIT

**Transformata Ca≈Çkowa Prawdopodobie≈Ñstwa**

Je≈õli prognozy sƒÖ dobrze skalibrowane:

```
u = F(r_actual)  powinno byƒá  ~ Uniform(0, 1)
```

**Po polsku:** *"Je≈õli podstawimy rzeczywiste wyniki do naszej prognozowanej dystrybuanty, wyniki powinny byƒá r√≥wnomiernie roz≈Ço≈ºone."*

**Test KS**

Obliczamy statystykƒô Ko≈Çmogorowa-Smirnowa:

```
KS = sup_u | F_empirical(u) - u |
```

**Po polsku:** *"Znajd≈∫ maksymalnƒÖ lukƒô miƒôdzy empirycznym rozk≈Çadem warto≈õci u a liniƒÖ r√≥wnomiernƒÖ."*

p-value > 0.05 wskazuje, ≈ºe kalibracja jest akceptowalna.

**Interpretacja**

| Wzorzec | Warto≈õƒá KS | Znaczenie |
|---------|------------|-----------|
| KS ‚âà 0 | < 0.05 | Idealna kalibracja ‚úì |
| KS umiarkowane | 0.05-0.10 | Mniejsza b≈Çƒôdna kalibracja |
| KS > 0.1 | > 0.10 | ZnaczƒÖca b≈Çƒôdna kalibracja ‚úó |

**Wzorce wizualne w histogramie PIT:**
- **Kszta≈Çt U** (warto≈õci grupujƒÖ siƒô przy 0 i 1): Nadmierna pewno≈õƒá ‚Äî prognozy sƒÖ zbyt wƒÖskie
- **Kszta≈Çt ‚à©** (warto≈õci grupujƒÖ siƒô w ≈õrodku): Niedostateczna pewno≈õƒá ‚Äî prognozy sƒÖ zbyt szerokie
- **P≈Çaski** (rozk≈Çad r√≥wnomierny): Dobrze skalibrowany ‚úì

---

### Podsumowanie: Kontrakt Matematyczny

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                                             ‚îÇ
‚îÇ   DANE:     r‚Çú = log(P‚Çú/P‚Çú‚Çã‚ÇÅ)                               ‚îÇ
‚îÇ             œÉ‚Çú¬≤ = EWMA(r‚Çú¬≤)                                 ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ   STROJENIE: Œº‚Çú = œÜŒº‚Çú‚Çã‚ÇÅ + Œ∑‚Çú       (r√≥wnanie stanu)         ‚îÇ
‚îÇ              r‚Çú = Œº‚Çú + Œµ‚Çú          (obserwacja)             ‚îÇ
‚îÇ              q* = argmax ‚Ñì(q)      (MLE)                    ‚îÇ
‚îÇ              p(m|r) ‚àù exp(-BIC/2)  (wagi BMA)               ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ   SYGNA≈Å:   p(r|dane) = Œ£‚Çò p(r|m,Œ∏) ¬∑ p(m|r)   (mieszanka) ‚îÇ
‚îÇ             P(r>0) = ‚à´‚ÇÄ^‚àû p(r) dr    (prawdopodobie≈Ñstwo)  ‚îÇ
‚îÇ             sygna≈Ç = map(P(r>0))     (decyzja)             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Matematyka jest systemem. Kod jedynie jƒÖ implementuje.**

---

## ≈öciƒÖgawka

### Pierwsza Konfiguracja
```bash
make setup              # Zainstaluj wszystko, pobierz dane
```

### Codzienne U≈ºycie
```bash
make stocks             # Jedna komenda, kt√≥rej potrzebujesz
```

### Cotygodniowa Konserwacja
```bash
make tune               # Przekalibruj parametry
make stocks             # Wygeneruj ≈õwie≈ºe sygna≈Çy
```

### Gdy Co≈õ Nie Dzia≈Ça
```bash
make doctor             # Przeinstaluj zale≈ºno≈õci
make failed             # Zobacz co siƒô nie uda≈Ço
make purge              # Wyczy≈õƒá cache nieudanych
make data               # Pobierz wszystko ponownie
```

### Tabela Szybkiej Referencji

| Chcƒô... | Komenda |
|---------|---------|
| Wygenerowaƒá sygna≈Çy | `make stocks` |
| Tylko zobaczyƒá zapisane sygna≈Çy | `make report` |
| Przekalibrowaƒá wszystkie parametry | `make tune ARGS="--force"` |
| Przetestowaƒá z kilkoma aktywami | `make top20` |
| Zwalidowaƒá kalibracjƒô | `make fx-calibration` |
| Wyczy≈õciƒá wszystko | `make clear` |
| Zobaczyƒá co siƒô nie uda≈Ço | `make failed` |
| Pracowaƒá offline | `OFFLINE_MODE=1 make stocks` |

---

## Filozofia

### G≈Ç√≥wna Zasada

> *"Dzia≈Çaj tylko na podstawie przekona≈Ñ, kt√≥re faktycznie zosta≈Çy wyuczone."*

Ten system to **silnik ewolucji przekona≈Ñ**. Utrzymuje konkurujƒÖce hipotezy o dynamice rynku i pozwala bayesowskiemu wnioskowaniu arbitrowaƒá miƒôdzy nimi.

### Co Czyni To Innym

| Tradycyjne Systemy | Ten System |
|--------------------|------------|
| Wybierz "najlepszy" model | Utrzymuj niepewno≈õƒá modelu |
| Punktowe estymacje | Pe≈Çne rozk≈Çady |
| Sta≈Çe parametry | CiƒÖgle przekalibrowywane |
| Pewno≈õƒá z przekonania | Pewno≈õƒá z kalibracji |
| Cicho zawodzƒÖ gdy b≈Çƒôdne | WiedzƒÖ, kiedy nie wiedzƒÖ |

### Trzy Prawa

1. **Nigdy nie wymy≈õlaj przekona≈Ñ.** Gdy dowody sƒÖ s≈Çabe, sta≈Ñ siƒô bardziej niewiedzƒÖcy ‚Äî nie bardziej pewny. Fallback jest zawsze hierarchiczny (re≈ºim ‚Üí globalny), nigdy sfabrykowany.

2. **Zachowaj integralno≈õƒá rozk≈ÇadowƒÖ.** Decyzje pochodzƒÖ z rozk≈Çad√≥w, nie punktowych estymacji. Warstwa sygna≈Ç√≥w widzi pr√≥bki, nie parametry.

3. **Oddziel epistemologiƒô od agencji.** Silnik Strojenia uczy siƒô przekona≈Ñ. Silnik Sygna≈Ç√≥w dzia≈Ça na ich podstawie. Nigdy siƒô nie mieszajƒÖ.

### Cel

**Skalibrowana niepewno≈õƒá**, nie fa≈Çszywa precyzja.

Gdy system m√≥wi "62% prawdopodobie≈Ñstwa," powinien mieƒá racjƒô w 62% przypadk√≥w. Nie 70%. Nie 55%. Dok≈Çadnie 62%.

To w≈Ça≈õnie weryfikujƒÖ testy kalibracji PIT. To sprawia, ≈ºe ten system jest godny zaufania.

---

## Licencja / License

This project is for educational and research purposes. See individual dependencies for their respective licenses.

Ten projekt s≈Çu≈ºy celom edukacyjnym i badawczym. Zobacz poszczeg√≥lne zale≈ºno≈õci dla ich odpowiednich licencji.

---

<p align="center">
  <sub>Built with scientific rigor and engineering craftsmanship.</sub>
</p>

<p align="center">
  <sub>Zbudowany z naukowƒÖ rygorem i rzemie≈õlniczym kunsztem.</sub>
</p>

<p align="center">
  <sub>The math is the system. The code merely implements it.</sub>
</p>

<p align="center">
  <sub>Matematyka jest systemem. Kod jedynie jƒÖ implementuje.</sub>
</p>